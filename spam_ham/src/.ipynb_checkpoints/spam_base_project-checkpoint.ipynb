{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66796d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 10:38:44.246762: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-10 10:38:44.246851: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy  as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f3c04",
   "metadata": {},
   "source": [
    "# Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c49fa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/spambase.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14681/1282884489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspam_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/spambase.csv\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspam_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/spambase.csv'"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "spam_data = pd.read_csv(\"../data/spambase.csv\",  sep = ',', header= None )\n",
    "print(spam_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cbd078",
   "metadata": {},
   "source": [
    "The colunmn names are integers so renaming the columns appropriately (column names are available at the UCI website here: https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abe5b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# renaming the columns\n",
    "spam_data.columns  = [\"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\", \n",
    "                      \"word_freq_our\", \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\", \n",
    "                      \"word_freq_order\", \"word_freq_mail\", \"word_freq_receive\", \"word_freq_will\", \n",
    "                      \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\", \"word_freq_free\", \n",
    "                      \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\", \n",
    "                      \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\", \"word_freq_hp\", \n",
    "                      \"word_freq_hpl\", \"word_freq_george\", \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\", \n",
    "                      \"word_freq_telnet\", \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\", \n",
    "                      \"word_freq_technology\", \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\",\n",
    "                      \"word_freq_cs\", \"word_freq_meeting\", \"word_freq_original\", \"word_freq_project\", \"word_freq_re\", \n",
    "                      \"word_freq_edu\", \"word_freq_table\", \"word_freq_conference\", \"char_freq_;\", \"char_freq_(\", \n",
    "                      \"char_freq_[\", \"char_freq_!\", \"char_freq_$\", \"char_freq_hash\", \"capital_run_length_average\", \n",
    "                      \"capital_run_length_longest\", \"capital_run_length_total\", \"spam\"]\n",
    "print(spam_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2792267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show the distribution of spam data\n",
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "spam_data['spam'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\n",
    "ax[0].set_title('Category')\n",
    "ax[0].set_ylabel('')\n",
    "sns.countplot('spam',data=spam_data,ax=ax[1])\n",
    "ax[1].set_title('Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efaa1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "sns.countplot(spam_data.spam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7569af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at dimensions of the df\n",
    "print(spam_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d7f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values in the dataset \n",
    "spam_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2692b28a",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Let's now conduct some prelimininary data preparation steps, i.e. rescaling the variables.Rescaling is required as some columns like e.g at the end (capital_run_length_longest, capital_run_length_total etc.) have much higher values (means = 52, 283 etc.) than most other columns which represent fraction of word occurrences (no. of times word appears in email/total no. of words in email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f643868",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into X and y in order to seperate labels from features\n",
    "X = spam_data.drop(\"spam\", axis = 1)\n",
    "y = spam_data.spam.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f232f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features\n",
    "# note that the scale function standardises each column, i.e.\n",
    "# x = x-mean(x)/std(x)\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "X = scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8e9773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29a001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that splitting also has similar distribution of spam and ham \n",
    "# emails\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3803d2f",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a6e2c",
   "metadata": {},
   "source": [
    "\n",
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the model architecture\n",
    "#A dropout layer is inserted  as a form of regularization \n",
    "#which will help reduce overfitting by randomly setting (here 30%) of the input unit values to zero.\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=9, activation=\"relu\", input_shape=(X_train.shape[-1],) ),\n",
    "        # randomly delete 30% of the input units below\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(units=9, activation=\"relu\"),\n",
    "        # the output layer, with a single neuron\n",
    "        keras.layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# save the initial weights for later\n",
    "initial_weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4809f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fbee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8638dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5875b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualkeras.layered_view(model, legend=True)  # font is optional!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "              loss=\"binary_crossentropy\", \n",
    "              metrics=keras.metrics.AUC()\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "          epochs=500, \n",
    "          batch_size=1000, \n",
    "          validation_data=(X_test, y_test),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38552162",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "Finding the co relation between features and with y label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the co relation between each feature and label\n",
    "# As the features are numerical and label is categorical so kendall is used to measure cor relation \n",
    "X = spam_data.drop(\"spam\", axis = 1)\n",
    "corr_action=X.corrwith(spam_data['spam'],method='kendall').abs()\n",
    "print(corr_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394373f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_action.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81172b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting those features whose co relation with dependent variable (y)\n",
    "relevant_num_features = corr_action[corr_action>0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b4ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_num_features_col=relevant_num_features.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7f806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_num_df = X[relevant_num_features_col]  # Only getting columns having corr> 0.3 wrt output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123df937",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_num_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e91c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To fing co relation between features\n",
    "pearson_corr = X.corr(method='pearson').abs()\n",
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(20,20))\n",
    "# cor = df.corr()\n",
    "sns.heatmap(pearson_corr, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25fa852",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_matrix = X.corr().abs()\n",
    "print(cor_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(np.bool))\n",
    "print(upper_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "print(); print(to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f4ee8f",
   "metadata": {},
   "source": [
    "# Part3\n",
    "Removing the significant features and building a fully connected classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59c17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"char_freq_!\",\"char_freq_$\",\"word_freq_remove\",\"word_freq_free\",\"word_freq_money\",\"word_freq_your\",\n",
    "\"capital_run_length_longest\",\"word_freq_000\",\"capital_run_length_average\",\"word_freq_hp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4d00cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping at are highly significant i.e those features that have large impact on y \n",
    "#splitting into X and y\n",
    "X_1 = spam_data.drop([\"char_freq_!\",\"char_freq_$\",\"word_freq_remove\",\"word_freq_free\",\"word_freq_money\",\"word_freq_your\",\n",
    "\"capital_run_length_longest\",\"word_freq_000\",\"capital_run_length_average\",\"word_freq_hp\",\"spam\"], axis = 1)\n",
    "y_1 =spam_data.spam.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc5708",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = scale(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b96ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_1, test_size = 0.3, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025348b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the model architecture\n",
    "#A dropout layer is inserted  as a form of regularization \n",
    "#which will help reduce overfitting by randomly setting (here 30%) of the input unit values to zero.\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=9, activation=\"relu\", input_shape=(X_train_1.shape[-1],) ),\n",
    "        # randomly delete 30% of the input units below\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(units=9, activation=\"relu\"),\n",
    "        # the output layer, with a single neuron\n",
    "        keras.layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# save the initial weights for later\n",
    "initial_weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809dc72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "              loss=\"binary_crossentropy\", \n",
    "              metrics=keras.metrics.AUC())\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90ef331",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_1, y_train_1, \n",
    "          epochs=500, \n",
    "          batch_size=1000, \n",
    "          validation_data=(X_test_1, y_test_1),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82274dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test data\n",
    "test_data = pd.read_csv(\"../test/test.csv\",  sep = ',', header= None )\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bb37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the class of data\n",
    "pred=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14499b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664d11f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
