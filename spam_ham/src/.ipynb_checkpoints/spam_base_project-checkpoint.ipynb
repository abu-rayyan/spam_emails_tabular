{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66796d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 11:24:07.883681: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-10 11:24:07.883702: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy  as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f3c04",
   "metadata": {},
   "source": [
    "# Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08c49fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     1     2    3     4     5     6     7     8     9   ...    48  \\\n",
      "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
      "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
      "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
      "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
      "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
      "\n",
      "      49   50     51     52     53     54   55    56  57  \n",
      "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
      "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
      "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
      "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
      "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "spam_data = pd.read_csv(\"../data/spambase.csv\",  sep = ',', header= None )\n",
    "print(spam_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cbd078",
   "metadata": {},
   "source": [
    "The colunmn names are integers so renaming the columns appropriately (column names are available at the UCI website here: https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2abe5b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
      "0            0.00               0.64           0.64           0.0   \n",
      "1            0.21               0.28           0.50           0.0   \n",
      "2            0.06               0.00           0.71           0.0   \n",
      "3            0.00               0.00           0.00           0.0   \n",
      "4            0.00               0.00           0.00           0.0   \n",
      "\n",
      "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
      "0           0.32            0.00              0.00                0.00   \n",
      "1           0.14            0.28              0.21                0.07   \n",
      "2           1.23            0.19              0.19                0.12   \n",
      "3           0.63            0.00              0.31                0.63   \n",
      "4           0.63            0.00              0.31                0.63   \n",
      "\n",
      "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
      "0             0.00            0.00  ...         0.00        0.000   \n",
      "1             0.00            0.94  ...         0.00        0.132   \n",
      "2             0.64            0.25  ...         0.01        0.143   \n",
      "3             0.31            0.63  ...         0.00        0.137   \n",
      "4             0.31            0.63  ...         0.00        0.135   \n",
      "\n",
      "   char_freq_[  char_freq_!  char_freq_$  char_freq_hash  \\\n",
      "0          0.0        0.778        0.000           0.000   \n",
      "1          0.0        0.372        0.180           0.048   \n",
      "2          0.0        0.276        0.184           0.010   \n",
      "3          0.0        0.137        0.000           0.000   \n",
      "4          0.0        0.135        0.000           0.000   \n",
      "\n",
      "   capital_run_length_average  capital_run_length_longest  \\\n",
      "0                       3.756                          61   \n",
      "1                       5.114                         101   \n",
      "2                       9.821                         485   \n",
      "3                       3.537                          40   \n",
      "4                       3.537                          40   \n",
      "\n",
      "   capital_run_length_total  spam  \n",
      "0                       278     1  \n",
      "1                      1028     1  \n",
      "2                      2259     1  \n",
      "3                       191     1  \n",
      "4                       191     1  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# renaming the columns\n",
    "spam_data.columns  = [\"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\", \n",
    "                      \"word_freq_our\", \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\", \n",
    "                      \"word_freq_order\", \"word_freq_mail\", \"word_freq_receive\", \"word_freq_will\", \n",
    "                      \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\", \"word_freq_free\", \n",
    "                      \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\", \n",
    "                      \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\", \"word_freq_hp\", \n",
    "                      \"word_freq_hpl\", \"word_freq_george\", \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\", \n",
    "                      \"word_freq_telnet\", \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\", \n",
    "                      \"word_freq_technology\", \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\",\n",
    "                      \"word_freq_cs\", \"word_freq_meeting\", \"word_freq_original\", \"word_freq_project\", \"word_freq_re\", \n",
    "                      \"word_freq_edu\", \"word_freq_table\", \"word_freq_conference\", \"char_freq_;\", \"char_freq_(\", \n",
    "                      \"char_freq_[\", \"char_freq_!\", \"char_freq_$\", \"char_freq_hash\", \"capital_run_length_average\", \n",
    "                      \"capital_run_length_longest\", \"capital_run_length_total\", \"spam\"]\n",
    "print(spam_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2792267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sajid/anaconda3/envs/py37/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#To show the distribution of spam data\n",
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "spam_data['spam'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\n",
    "ax[0].set_title('Category')\n",
    "ax[0].set_ylabel('')\n",
    "sns.countplot('spam',data=spam_data,ax=ax[1])\n",
    "ax[1].set_title('Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8efaa1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sajid/anaconda3/envs/py37/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='spam', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "sns.countplot(spam_data.spam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f7569af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 58)\n"
     ]
    }
   ],
   "source": [
    "# look at dimensions of the df\n",
    "print(spam_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09d7f098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                0\n",
       "word_freq_address             0\n",
       "word_freq_all                 0\n",
       "word_freq_3d                  0\n",
       "word_freq_our                 0\n",
       "word_freq_over                0\n",
       "word_freq_remove              0\n",
       "word_freq_internet            0\n",
       "word_freq_order               0\n",
       "word_freq_mail                0\n",
       "word_freq_receive             0\n",
       "word_freq_will                0\n",
       "word_freq_people              0\n",
       "word_freq_report              0\n",
       "word_freq_addresses           0\n",
       "word_freq_free                0\n",
       "word_freq_business            0\n",
       "word_freq_email               0\n",
       "word_freq_you                 0\n",
       "word_freq_credit              0\n",
       "word_freq_your                0\n",
       "word_freq_font                0\n",
       "word_freq_000                 0\n",
       "word_freq_money               0\n",
       "word_freq_hp                  0\n",
       "word_freq_hpl                 0\n",
       "word_freq_george              0\n",
       "word_freq_650                 0\n",
       "word_freq_lab                 0\n",
       "word_freq_labs                0\n",
       "word_freq_telnet              0\n",
       "word_freq_857                 0\n",
       "word_freq_data                0\n",
       "word_freq_415                 0\n",
       "word_freq_85                  0\n",
       "word_freq_technology          0\n",
       "word_freq_1999                0\n",
       "word_freq_parts               0\n",
       "word_freq_pm                  0\n",
       "word_freq_direct              0\n",
       "word_freq_cs                  0\n",
       "word_freq_meeting             0\n",
       "word_freq_original            0\n",
       "word_freq_project             0\n",
       "word_freq_re                  0\n",
       "word_freq_edu                 0\n",
       "word_freq_table               0\n",
       "word_freq_conference          0\n",
       "char_freq_;                   0\n",
       "char_freq_(                   0\n",
       "char_freq_[                   0\n",
       "char_freq_!                   0\n",
       "char_freq_$                   0\n",
       "char_freq_hash                0\n",
       "capital_run_length_average    0\n",
       "capital_run_length_longest    0\n",
       "capital_run_length_total      0\n",
       "spam                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in the dataset \n",
    "spam_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2692b28a",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Let's now conduct some prelimininary data preparation steps, i.e. rescaling the variables.Rescaling is required as some columns like e.g at the end (capital_run_length_longest, capital_run_length_total etc.) have much higher values (means = 52, 283 etc.) than most other columns which represent fraction of word occurrences (no. of times word appears in email/total no. of words in email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f643868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_hash</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean         0.104553           0.213015       0.280656      0.065425   \n",
       "std          0.305358           1.290575       0.504143      1.395151   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.420000      0.000000   \n",
       "max          4.540000          14.280000       5.100000     42.810000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean        0.312223        0.095901          0.114208            0.105295   \n",
       "std         0.672513        0.273824          0.391441            0.401071   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.380000        0.000000          0.000000            0.000000   \n",
       "max        10.000000        5.880000          7.270000           11.110000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "count      4601.000000     4601.000000  ...  4601.000000  4601.000000   \n",
       "mean          0.090067        0.239413  ...     0.038575     0.139030   \n",
       "std           0.278616        0.644755  ...     0.243471     0.270355   \n",
       "min           0.000000        0.000000  ...     0.000000     0.000000   \n",
       "25%           0.000000        0.000000  ...     0.000000     0.000000   \n",
       "50%           0.000000        0.000000  ...     0.000000     0.065000   \n",
       "75%           0.000000        0.160000  ...     0.000000     0.188000   \n",
       "max           5.260000       18.180000  ...     4.385000     9.752000   \n",
       "\n",
       "       char_freq_[  char_freq_!  char_freq_$  char_freq_hash  \\\n",
       "count  4601.000000  4601.000000  4601.000000     4601.000000   \n",
       "mean      0.016976     0.269071     0.075811        0.044238   \n",
       "std       0.109394     0.815672     0.245882        0.429342   \n",
       "min       0.000000     0.000000     0.000000        0.000000   \n",
       "25%       0.000000     0.000000     0.000000        0.000000   \n",
       "50%       0.000000     0.000000     0.000000        0.000000   \n",
       "75%       0.000000     0.315000     0.052000        0.000000   \n",
       "max       4.081000    32.478000     6.003000       19.829000   \n",
       "\n",
       "       capital_run_length_average  capital_run_length_longest  \\\n",
       "count                 4601.000000                 4601.000000   \n",
       "mean                     5.191515                   52.172789   \n",
       "std                     31.729449                  194.891310   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      1.588000                    6.000000   \n",
       "50%                      2.276000                   15.000000   \n",
       "75%                      3.706000                   43.000000   \n",
       "max                   1102.500000                 9989.000000   \n",
       "\n",
       "       capital_run_length_total         spam  \n",
       "count               4601.000000  4601.000000  \n",
       "mean                 283.289285     0.394045  \n",
       "std                  606.347851     0.488698  \n",
       "min                    1.000000     0.000000  \n",
       "25%                   35.000000     0.000000  \n",
       "50%                   95.000000     0.000000  \n",
       "75%                  266.000000     1.000000  \n",
       "max                15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "191a7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into X and y in order to seperate labels from features\n",
    "x= spam_data.drop(\"spam\", axis = 1)\n",
    "y = spam_data.spam.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3f232f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features\n",
    "# note that the scale function standardises each column, i.e.\n",
    "# x = x-mean(x)/std(x)\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "x = scale(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f8e9773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f29a001f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3978260869565217\n",
      "0.38522809558291093\n"
     ]
    }
   ],
   "source": [
    "# confirm that splitting also has similar distribution of spam and ham \n",
    "# emails\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3803d2f",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a6e2c",
   "metadata": {},
   "source": [
    "\n",
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dd8a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 11:24:40.124718: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-10 11:24:40.124747: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-10 11:24:40.124767: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sajid): /proc/driver/nvidia/version does not exist\n",
      "2022-03-10 11:24:40.124969: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Defining the model architecture\n",
    "#A dropout layer is inserted  as a form of regularization \n",
    "#which will help reduce overfitting by randomly setting (here 30%) of the input unit values to zero.\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=9, activation=\"relu\", input_shape=(x_train.shape[-1],) ),\n",
    "        # randomly delete 30% of the input units below\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(units=9, activation=\"relu\"),\n",
    "        # the output layer, with a single neuron\n",
    "        keras.layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# save the initial weights for later\n",
    "initial_weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4809f8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 9)                 522       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 9)                 90        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 622\n",
      "Trainable params: 622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60fbee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8638dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5875b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=137x89 at 0x7FB0CC2B7710>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualkeras.layered_view(model, legend=True)  # font is optional!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9239ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "              loss=\"binary_crossentropy\", \n",
    "              metrics=keras.metrics.AUC()\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db74bdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fb0c8104830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fb0c8104830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/4 [======>.......................] - ETA: 1s - loss: 0.7811 - auc: 0.5025WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fb0b019e3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fb0b019e3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4/4 [==============================] - 1s 73ms/step - loss: 0.8056 - auc: 0.4710 - val_loss: 0.8092 - val_auc: 0.5060\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7643 - auc: 0.5101 - val_loss: 0.7796 - val_auc: 0.5398\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7461 - auc: 0.5339 - val_loss: 0.7531 - val_auc: 0.5729\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7255 - auc: 0.5590 - val_loss: 0.7284 - val_auc: 0.6023\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7045 - auc: 0.5857 - val_loss: 0.7056 - val_auc: 0.6334\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6874 - auc: 0.6319 - val_loss: 0.6861 - val_auc: 0.6634\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6745 - auc: 0.6487 - val_loss: 0.6684 - val_auc: 0.6896\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6546 - auc: 0.6761 - val_loss: 0.6513 - val_auc: 0.7144\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6497 - auc: 0.6885 - val_loss: 0.6353 - val_auc: 0.7365\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6411 - auc: 0.7011 - val_loss: 0.6202 - val_auc: 0.7587\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6222 - auc: 0.7363 - val_loss: 0.6061 - val_auc: 0.7779\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6145 - auc: 0.7538 - val_loss: 0.5926 - val_auc: 0.7960\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5991 - auc: 0.7832 - val_loss: 0.5800 - val_auc: 0.8144\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5938 - auc: 0.7835 - val_loss: 0.5680 - val_auc: 0.8340\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5863 - auc: 0.7923 - val_loss: 0.5564 - val_auc: 0.8471\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5686 - auc: 0.8180 - val_loss: 0.5450 - val_auc: 0.8574\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5578 - auc: 0.8264 - val_loss: 0.5338 - val_auc: 0.8671\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5478 - auc: 0.8408 - val_loss: 0.5227 - val_auc: 0.8749\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5427 - auc: 0.8408 - val_loss: 0.5116 - val_auc: 0.8819\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5304 - auc: 0.8516 - val_loss: 0.5005 - val_auc: 0.8883\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5176 - auc: 0.8645 - val_loss: 0.4895 - val_auc: 0.8942\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5050 - auc: 0.8788 - val_loss: 0.4785 - val_auc: 0.8991\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4992 - auc: 0.8752 - val_loss: 0.4674 - val_auc: 0.9040\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4885 - auc: 0.8850 - val_loss: 0.4566 - val_auc: 0.9085\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4726 - auc: 0.8946 - val_loss: 0.4458 - val_auc: 0.9128\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4681 - auc: 0.8958 - val_loss: 0.4354 - val_auc: 0.9161\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4610 - auc: 0.8943 - val_loss: 0.4251 - val_auc: 0.9192\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4505 - auc: 0.9020 - val_loss: 0.4152 - val_auc: 0.9217\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4353 - auc: 0.9100 - val_loss: 0.4058 - val_auc: 0.9239\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4305 - auc: 0.9132 - val_loss: 0.3968 - val_auc: 0.9260\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4213 - auc: 0.9172 - val_loss: 0.3883 - val_auc: 0.9276\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4188 - auc: 0.9128 - val_loss: 0.3800 - val_auc: 0.9292\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3988 - auc: 0.9252 - val_loss: 0.3723 - val_auc: 0.9305\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3901 - auc: 0.9265 - val_loss: 0.3648 - val_auc: 0.9317\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3886 - auc: 0.9265 - val_loss: 0.3579 - val_auc: 0.9329\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3816 - auc: 0.9266 - val_loss: 0.3515 - val_auc: 0.9337\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3691 - auc: 0.9331 - val_loss: 0.3456 - val_auc: 0.9347\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3691 - auc: 0.9298 - val_loss: 0.3400 - val_auc: 0.9356\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3646 - auc: 0.9322 - val_loss: 0.3348 - val_auc: 0.9365\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3514 - auc: 0.9365 - val_loss: 0.3299 - val_auc: 0.9373\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3446 - auc: 0.9392 - val_loss: 0.3254 - val_auc: 0.9383\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3499 - auc: 0.9323 - val_loss: 0.3212 - val_auc: 0.9390\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3355 - auc: 0.9404 - val_loss: 0.3173 - val_auc: 0.9397\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3379 - auc: 0.9374 - val_loss: 0.3135 - val_auc: 0.9405\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3361 - auc: 0.9386 - val_loss: 0.3099 - val_auc: 0.9412\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3326 - auc: 0.9392 - val_loss: 0.3066 - val_auc: 0.9421\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3219 - auc: 0.9427 - val_loss: 0.3033 - val_auc: 0.9427\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3179 - auc: 0.9431 - val_loss: 0.3000 - val_auc: 0.9434\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3193 - auc: 0.9423 - val_loss: 0.2970 - val_auc: 0.9443\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3141 - auc: 0.9439 - val_loss: 0.2942 - val_auc: 0.9450\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3047 - auc: 0.9472 - val_loss: 0.2915 - val_auc: 0.9455\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3084 - auc: 0.9447 - val_loss: 0.2891 - val_auc: 0.9463\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3060 - auc: 0.9453 - val_loss: 0.2867 - val_auc: 0.9467\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3031 - auc: 0.9455 - val_loss: 0.2845 - val_auc: 0.9475\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3017 - auc: 0.9451 - val_loss: 0.2824 - val_auc: 0.9481\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2931 - auc: 0.9499 - val_loss: 0.2805 - val_auc: 0.9488\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2872 - auc: 0.9503 - val_loss: 0.2787 - val_auc: 0.9492\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2885 - auc: 0.9500 - val_loss: 0.2770 - val_auc: 0.9499\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2855 - auc: 0.9518 - val_loss: 0.2753 - val_auc: 0.9502\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2803 - auc: 0.9515 - val_loss: 0.2736 - val_auc: 0.9510\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2808 - auc: 0.9537 - val_loss: 0.2720 - val_auc: 0.9515\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2725 - auc: 0.9550 - val_loss: 0.2705 - val_auc: 0.9520\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2797 - auc: 0.9523 - val_loss: 0.2692 - val_auc: 0.9527\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2710 - auc: 0.9561 - val_loss: 0.2679 - val_auc: 0.9531\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2686 - auc: 0.9550 - val_loss: 0.2666 - val_auc: 0.9538\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2712 - auc: 0.9549 - val_loss: 0.2655 - val_auc: 0.9542\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2637 - auc: 0.9567 - val_loss: 0.2645 - val_auc: 0.9547\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2567 - auc: 0.9601 - val_loss: 0.2635 - val_auc: 0.9552\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2684 - auc: 0.9560 - val_loss: 0.2626 - val_auc: 0.9555\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2710 - auc: 0.9544 - val_loss: 0.2617 - val_auc: 0.9559\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2544 - auc: 0.9595 - val_loss: 0.2607 - val_auc: 0.9561\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2578 - auc: 0.9588 - val_loss: 0.2598 - val_auc: 0.9567\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2633 - auc: 0.9568 - val_loss: 0.2588 - val_auc: 0.9570\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2586 - auc: 0.9584 - val_loss: 0.2579 - val_auc: 0.9574\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2591 - auc: 0.9579 - val_loss: 0.2572 - val_auc: 0.9576\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2558 - auc: 0.9593 - val_loss: 0.2564 - val_auc: 0.9580\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2492 - auc: 0.9616 - val_loss: 0.2557 - val_auc: 0.9582\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2543 - auc: 0.9592 - val_loss: 0.2548 - val_auc: 0.9587\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2532 - auc: 0.9591 - val_loss: 0.2539 - val_auc: 0.9590\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2505 - auc: 0.9613 - val_loss: 0.2533 - val_auc: 0.9595\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2519 - auc: 0.9603 - val_loss: 0.2526 - val_auc: 0.9598\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2424 - auc: 0.9630 - val_loss: 0.2520 - val_auc: 0.9600\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2398 - auc: 0.9635 - val_loss: 0.2515 - val_auc: 0.9603\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2431 - auc: 0.9627 - val_loss: 0.2512 - val_auc: 0.9604\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2416 - auc: 0.9627 - val_loss: 0.2508 - val_auc: 0.9606\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2369 - auc: 0.9640 - val_loss: 0.2504 - val_auc: 0.9609\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2367 - auc: 0.9648 - val_loss: 0.2500 - val_auc: 0.9611\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2361 - auc: 0.9655 - val_loss: 0.2496 - val_auc: 0.9613\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2402 - auc: 0.9641 - val_loss: 0.2491 - val_auc: 0.9616\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2376 - auc: 0.9648 - val_loss: 0.2487 - val_auc: 0.9618\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2408 - auc: 0.9643 - val_loss: 0.2483 - val_auc: 0.9620\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2293 - auc: 0.9669 - val_loss: 0.2478 - val_auc: 0.9621\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2353 - auc: 0.9644 - val_loss: 0.2473 - val_auc: 0.9624\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2270 - auc: 0.9680 - val_loss: 0.2469 - val_auc: 0.9627\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2226 - auc: 0.9688 - val_loss: 0.2465 - val_auc: 0.9627\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2378 - auc: 0.9648 - val_loss: 0.2461 - val_auc: 0.9629\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2309 - auc: 0.9669 - val_loss: 0.2457 - val_auc: 0.9630\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2318 - auc: 0.9662 - val_loss: 0.2453 - val_auc: 0.9632\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2278 - auc: 0.9674 - val_loss: 0.2450 - val_auc: 0.9634\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2309 - auc: 0.9661 - val_loss: 0.2447 - val_auc: 0.9636\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2303 - auc: 0.9663 - val_loss: 0.2446 - val_auc: 0.9638\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2313 - auc: 0.9663 - val_loss: 0.2445 - val_auc: 0.9638\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2241 - auc: 0.9682 - val_loss: 0.2443 - val_auc: 0.9640\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2294 - auc: 0.9672 - val_loss: 0.2441 - val_auc: 0.9641\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2231 - auc: 0.9685 - val_loss: 0.2439 - val_auc: 0.9643\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2206 - auc: 0.9702 - val_loss: 0.2437 - val_auc: 0.9644\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2236 - auc: 0.9678 - val_loss: 0.2434 - val_auc: 0.9643\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2218 - auc: 0.9691 - val_loss: 0.2431 - val_auc: 0.9645\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2215 - auc: 0.9686 - val_loss: 0.2427 - val_auc: 0.9646\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2194 - auc: 0.9691 - val_loss: 0.2424 - val_auc: 0.9647\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2324 - auc: 0.9658 - val_loss: 0.2420 - val_auc: 0.9649\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2141 - auc: 0.9708 - val_loss: 0.2416 - val_auc: 0.9650\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2172 - auc: 0.9705 - val_loss: 0.2413 - val_auc: 0.9652\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2067 - auc: 0.9730 - val_loss: 0.2410 - val_auc: 0.9653\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2208 - auc: 0.9692 - val_loss: 0.2408 - val_auc: 0.9654\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.2121 - auc: 0.9717 - val_loss: 0.2406 - val_auc: 0.9656\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2103 - auc: 0.9721 - val_loss: 0.2403 - val_auc: 0.9657\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2196 - auc: 0.9688 - val_loss: 0.2400 - val_auc: 0.9659\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2194 - auc: 0.9694 - val_loss: 0.2397 - val_auc: 0.9661\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2136 - auc: 0.9708 - val_loss: 0.2394 - val_auc: 0.9663\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2133 - auc: 0.9711 - val_loss: 0.2391 - val_auc: 0.9665\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2116 - auc: 0.9719 - val_loss: 0.2387 - val_auc: 0.9665\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2105 - auc: 0.9715 - val_loss: 0.2386 - val_auc: 0.9664\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2151 - auc: 0.9705 - val_loss: 0.2384 - val_auc: 0.9666\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2181 - auc: 0.9690 - val_loss: 0.2382 - val_auc: 0.9668\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2095 - auc: 0.9725 - val_loss: 0.2382 - val_auc: 0.9669\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2133 - auc: 0.9707 - val_loss: 0.2381 - val_auc: 0.9669\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2071 - auc: 0.9720 - val_loss: 0.2379 - val_auc: 0.9670\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2106 - auc: 0.9718 - val_loss: 0.2376 - val_auc: 0.9670\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2130 - auc: 0.9715 - val_loss: 0.2372 - val_auc: 0.9670\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2086 - auc: 0.9725 - val_loss: 0.2369 - val_auc: 0.9671\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2101 - auc: 0.9723 - val_loss: 0.2367 - val_auc: 0.9672\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2055 - auc: 0.9732 - val_loss: 0.2365 - val_auc: 0.9673\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1993 - auc: 0.9748 - val_loss: 0.2363 - val_auc: 0.9673\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2061 - auc: 0.9724 - val_loss: 0.2361 - val_auc: 0.9674\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2020 - auc: 0.9737 - val_loss: 0.2360 - val_auc: 0.9676\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2025 - auc: 0.9736 - val_loss: 0.2359 - val_auc: 0.9677\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2066 - auc: 0.9722 - val_loss: 0.2357 - val_auc: 0.9677\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1972 - auc: 0.9752 - val_loss: 0.2356 - val_auc: 0.9678\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2054 - auc: 0.9731 - val_loss: 0.2355 - val_auc: 0.9679\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1998 - auc: 0.9747 - val_loss: 0.2353 - val_auc: 0.9680\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2024 - auc: 0.9736 - val_loss: 0.2351 - val_auc: 0.9680\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2045 - auc: 0.9736 - val_loss: 0.2349 - val_auc: 0.9682\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2061 - auc: 0.9728 - val_loss: 0.2346 - val_auc: 0.9682\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2037 - auc: 0.9732 - val_loss: 0.2342 - val_auc: 0.9685\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2070 - auc: 0.9726 - val_loss: 0.2337 - val_auc: 0.9686\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1994 - auc: 0.9753 - val_loss: 0.2334 - val_auc: 0.9687\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1937 - auc: 0.9766 - val_loss: 0.2332 - val_auc: 0.9687\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2060 - auc: 0.9731 - val_loss: 0.2329 - val_auc: 0.9688\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1953 - auc: 0.9757 - val_loss: 0.2326 - val_auc: 0.9689\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1947 - auc: 0.9760 - val_loss: 0.2324 - val_auc: 0.9690\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2040 - auc: 0.9734 - val_loss: 0.2318 - val_auc: 0.9690\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1991 - auc: 0.9747 - val_loss: 0.2315 - val_auc: 0.9690\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2058 - auc: 0.9727 - val_loss: 0.2313 - val_auc: 0.9691\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1996 - auc: 0.9741 - val_loss: 0.2311 - val_auc: 0.9691\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2019 - auc: 0.9740 - val_loss: 0.2310 - val_auc: 0.9691\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2035 - auc: 0.9737 - val_loss: 0.2308 - val_auc: 0.9692\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2064 - auc: 0.9729 - val_loss: 0.2303 - val_auc: 0.9693\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1931 - auc: 0.9761 - val_loss: 0.2298 - val_auc: 0.9694\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1973 - auc: 0.9756 - val_loss: 0.2295 - val_auc: 0.9694\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1972 - auc: 0.9754 - val_loss: 0.2291 - val_auc: 0.9696\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1955 - auc: 0.9754 - val_loss: 0.2288 - val_auc: 0.9696\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1912 - auc: 0.9766 - val_loss: 0.2288 - val_auc: 0.9697\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1978 - auc: 0.9752 - val_loss: 0.2287 - val_auc: 0.9698\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1957 - auc: 0.9756 - val_loss: 0.2286 - val_auc: 0.9698\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1910 - auc: 0.9764 - val_loss: 0.2284 - val_auc: 0.9699\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1988 - auc: 0.9745 - val_loss: 0.2282 - val_auc: 0.9700\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1975 - auc: 0.9753 - val_loss: 0.2280 - val_auc: 0.9700\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1948 - auc: 0.9761 - val_loss: 0.2277 - val_auc: 0.9701\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1985 - auc: 0.9749 - val_loss: 0.2274 - val_auc: 0.9702\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1949 - auc: 0.9752 - val_loss: 0.2271 - val_auc: 0.9703\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1954 - auc: 0.9755 - val_loss: 0.2268 - val_auc: 0.9704\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1941 - auc: 0.9762 - val_loss: 0.2265 - val_auc: 0.9704\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1920 - auc: 0.9769 - val_loss: 0.2262 - val_auc: 0.9704\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1885 - auc: 0.9772 - val_loss: 0.2260 - val_auc: 0.9705\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1986 - auc: 0.9751 - val_loss: 0.2256 - val_auc: 0.9707\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1940 - auc: 0.9761 - val_loss: 0.2252 - val_auc: 0.9707\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1951 - auc: 0.9757 - val_loss: 0.2249 - val_auc: 0.9707\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1970 - auc: 0.9753 - val_loss: 0.2247 - val_auc: 0.9707\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1850 - auc: 0.9785 - val_loss: 0.2246 - val_auc: 0.9707\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1876 - auc: 0.9780 - val_loss: 0.2246 - val_auc: 0.9707\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1934 - auc: 0.9764 - val_loss: 0.2245 - val_auc: 0.9706\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1867 - auc: 0.9774 - val_loss: 0.2243 - val_auc: 0.9706\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1898 - auc: 0.9770 - val_loss: 0.2240 - val_auc: 0.9708\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1934 - auc: 0.9759 - val_loss: 0.2238 - val_auc: 0.9709\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1912 - auc: 0.9765 - val_loss: 0.2236 - val_auc: 0.9709\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1870 - auc: 0.9776 - val_loss: 0.2233 - val_auc: 0.9709\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1903 - auc: 0.9765 - val_loss: 0.2230 - val_auc: 0.9710\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1936 - auc: 0.9759 - val_loss: 0.2225 - val_auc: 0.9711\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1909 - auc: 0.9771 - val_loss: 0.2220 - val_auc: 0.9711\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1882 - auc: 0.9773 - val_loss: 0.2214 - val_auc: 0.9714\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1884 - auc: 0.9775 - val_loss: 0.2209 - val_auc: 0.9715\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1856 - auc: 0.9777 - val_loss: 0.2204 - val_auc: 0.9715\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1875 - auc: 0.9771 - val_loss: 0.2201 - val_auc: 0.9716\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1867 - auc: 0.9775 - val_loss: 0.2197 - val_auc: 0.9716\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1826 - auc: 0.9784 - val_loss: 0.2193 - val_auc: 0.9717\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1913 - auc: 0.9766 - val_loss: 0.2190 - val_auc: 0.9717\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1835 - auc: 0.9783 - val_loss: 0.2185 - val_auc: 0.9719\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1819 - auc: 0.9783 - val_loss: 0.2182 - val_auc: 0.9718\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1862 - auc: 0.9778 - val_loss: 0.2179 - val_auc: 0.9718\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1882 - auc: 0.9774 - val_loss: 0.2177 - val_auc: 0.9720\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1840 - auc: 0.9783 - val_loss: 0.2175 - val_auc: 0.9720\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1825 - auc: 0.9786 - val_loss: 0.2172 - val_auc: 0.9720\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1814 - auc: 0.9790 - val_loss: 0.2167 - val_auc: 0.9721\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1832 - auc: 0.9785 - val_loss: 0.2164 - val_auc: 0.9720\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1861 - auc: 0.9784 - val_loss: 0.2161 - val_auc: 0.9721\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1853 - auc: 0.9777 - val_loss: 0.2159 - val_auc: 0.9721\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1767 - auc: 0.9803 - val_loss: 0.2155 - val_auc: 0.9722\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1836 - auc: 0.9783 - val_loss: 0.2152 - val_auc: 0.9722\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1802 - auc: 0.9795 - val_loss: 0.2149 - val_auc: 0.9723\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1833 - auc: 0.9783 - val_loss: 0.2147 - val_auc: 0.9722\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1843 - auc: 0.9780 - val_loss: 0.2144 - val_auc: 0.9722\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1783 - auc: 0.9798 - val_loss: 0.2142 - val_auc: 0.9723\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1807 - auc: 0.9790 - val_loss: 0.2139 - val_auc: 0.9723\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1804 - auc: 0.9787 - val_loss: 0.2135 - val_auc: 0.9725\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1781 - auc: 0.9795 - val_loss: 0.2133 - val_auc: 0.9725\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1808 - auc: 0.9787 - val_loss: 0.2132 - val_auc: 0.9726\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1835 - auc: 0.9782 - val_loss: 0.2130 - val_auc: 0.9726\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1786 - auc: 0.9794 - val_loss: 0.2130 - val_auc: 0.9727\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1781 - auc: 0.9795 - val_loss: 0.2131 - val_auc: 0.9727\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1822 - auc: 0.9788 - val_loss: 0.2132 - val_auc: 0.9727\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1797 - auc: 0.9788 - val_loss: 0.2132 - val_auc: 0.9726\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1794 - auc: 0.9791 - val_loss: 0.2131 - val_auc: 0.9727\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1775 - auc: 0.9795 - val_loss: 0.2131 - val_auc: 0.9727\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1835 - auc: 0.9783 - val_loss: 0.2132 - val_auc: 0.9727\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1761 - auc: 0.9795 - val_loss: 0.2132 - val_auc: 0.9727\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1777 - auc: 0.9795 - val_loss: 0.2130 - val_auc: 0.9727\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1774 - auc: 0.9797 - val_loss: 0.2129 - val_auc: 0.9728\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1774 - auc: 0.9795 - val_loss: 0.2127 - val_auc: 0.9728\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1796 - auc: 0.9795 - val_loss: 0.2125 - val_auc: 0.9728\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1768 - auc: 0.9797 - val_loss: 0.2125 - val_auc: 0.9728\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1739 - auc: 0.9805 - val_loss: 0.2126 - val_auc: 0.9728\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1791 - auc: 0.9795 - val_loss: 0.2128 - val_auc: 0.9728\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1766 - auc: 0.9794 - val_loss: 0.2129 - val_auc: 0.9729\n",
      "Epoch 235/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1702 - auc: 0.9810 - val_loss: 0.2130 - val_auc: 0.9727\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1739 - auc: 0.9806 - val_loss: 0.2129 - val_auc: 0.9728\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1774 - auc: 0.9794 - val_loss: 0.2126 - val_auc: 0.9729\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1688 - auc: 0.9816 - val_loss: 0.2124 - val_auc: 0.9729\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1727 - auc: 0.9807 - val_loss: 0.2123 - val_auc: 0.9730\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1748 - auc: 0.9799 - val_loss: 0.2124 - val_auc: 0.9729\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1732 - auc: 0.9804 - val_loss: 0.2124 - val_auc: 0.9730\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1722 - auc: 0.9811 - val_loss: 0.2123 - val_auc: 0.9729\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1741 - auc: 0.9805 - val_loss: 0.2123 - val_auc: 0.9731\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1699 - auc: 0.9815 - val_loss: 0.2122 - val_auc: 0.9730\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1718 - auc: 0.9812 - val_loss: 0.2119 - val_auc: 0.9731\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1729 - auc: 0.9805 - val_loss: 0.2117 - val_auc: 0.9732\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1766 - auc: 0.9794 - val_loss: 0.2116 - val_auc: 0.9732\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1737 - auc: 0.9800 - val_loss: 0.2116 - val_auc: 0.9727\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1747 - auc: 0.9800 - val_loss: 0.2117 - val_auc: 0.9727\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1697 - auc: 0.9818 - val_loss: 0.2119 - val_auc: 0.9728\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1675 - auc: 0.9816 - val_loss: 0.2120 - val_auc: 0.9727\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1746 - auc: 0.9802 - val_loss: 0.2119 - val_auc: 0.9727\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1774 - auc: 0.9794 - val_loss: 0.2118 - val_auc: 0.9727\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1763 - auc: 0.9795 - val_loss: 0.2117 - val_auc: 0.9727\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1746 - auc: 0.9796 - val_loss: 0.2114 - val_auc: 0.9727\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1704 - auc: 0.9812 - val_loss: 0.2111 - val_auc: 0.9727\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1719 - auc: 0.9807 - val_loss: 0.2108 - val_auc: 0.9727\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1716 - auc: 0.9812 - val_loss: 0.2107 - val_auc: 0.9727\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1719 - auc: 0.9811 - val_loss: 0.2106 - val_auc: 0.9727\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1738 - auc: 0.9803 - val_loss: 0.2105 - val_auc: 0.9728\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1691 - auc: 0.9815 - val_loss: 0.2105 - val_auc: 0.9727\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1786 - auc: 0.9791 - val_loss: 0.2104 - val_auc: 0.9728\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1730 - auc: 0.9804 - val_loss: 0.2101 - val_auc: 0.9728\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1664 - auc: 0.9817 - val_loss: 0.2100 - val_auc: 0.9729\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1721 - auc: 0.9805 - val_loss: 0.2100 - val_auc: 0.9729\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1683 - auc: 0.9822 - val_loss: 0.2102 - val_auc: 0.9730\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1712 - auc: 0.9809 - val_loss: 0.2103 - val_auc: 0.9730\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1680 - auc: 0.9816 - val_loss: 0.2103 - val_auc: 0.9730\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1692 - auc: 0.9813 - val_loss: 0.2104 - val_auc: 0.9730\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1643 - auc: 0.9827 - val_loss: 0.2104 - val_auc: 0.9731\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1710 - auc: 0.9810 - val_loss: 0.2104 - val_auc: 0.9731\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1665 - auc: 0.9818 - val_loss: 0.2103 - val_auc: 0.9730\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1696 - auc: 0.9812 - val_loss: 0.2102 - val_auc: 0.9730\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1706 - auc: 0.9812 - val_loss: 0.2101 - val_auc: 0.9730\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1709 - auc: 0.9810 - val_loss: 0.2100 - val_auc: 0.9731\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1676 - auc: 0.9816 - val_loss: 0.2098 - val_auc: 0.9732\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1599 - auc: 0.9830 - val_loss: 0.2096 - val_auc: 0.9732\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1639 - auc: 0.9825 - val_loss: 0.2097 - val_auc: 0.9732\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1775 - auc: 0.9798 - val_loss: 0.2096 - val_auc: 0.9732\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1677 - auc: 0.9815 - val_loss: 0.2097 - val_auc: 0.9731\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1641 - auc: 0.9819 - val_loss: 0.2098 - val_auc: 0.9731\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1681 - auc: 0.9822 - val_loss: 0.2098 - val_auc: 0.9732\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1651 - auc: 0.9822 - val_loss: 0.2096 - val_auc: 0.9732\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1660 - auc: 0.9820 - val_loss: 0.2094 - val_auc: 0.9733\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1742 - auc: 0.9806 - val_loss: 0.2090 - val_auc: 0.9732\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1657 - auc: 0.9824 - val_loss: 0.2088 - val_auc: 0.9732\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1698 - auc: 0.9813 - val_loss: 0.2087 - val_auc: 0.9733\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1627 - auc: 0.9826 - val_loss: 0.2085 - val_auc: 0.9733\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1629 - auc: 0.9824 - val_loss: 0.2081 - val_auc: 0.9733\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1640 - auc: 0.9824 - val_loss: 0.2080 - val_auc: 0.9734\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1677 - auc: 0.9819 - val_loss: 0.2078 - val_auc: 0.9735\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1663 - auc: 0.9822 - val_loss: 0.2078 - val_auc: 0.9735\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1638 - auc: 0.9827 - val_loss: 0.2079 - val_auc: 0.9735\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1657 - auc: 0.9825 - val_loss: 0.2080 - val_auc: 0.9736\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1650 - auc: 0.9822 - val_loss: 0.2082 - val_auc: 0.9729\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1673 - auc: 0.9815 - val_loss: 0.2085 - val_auc: 0.9730\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1656 - auc: 0.9821 - val_loss: 0.2084 - val_auc: 0.9730\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1692 - auc: 0.9811 - val_loss: 0.2082 - val_auc: 0.9731\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1685 - auc: 0.9814 - val_loss: 0.2078 - val_auc: 0.9737\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1624 - auc: 0.9823 - val_loss: 0.2074 - val_auc: 0.9737\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1603 - auc: 0.9835 - val_loss: 0.2073 - val_auc: 0.9737\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1641 - auc: 0.9826 - val_loss: 0.2073 - val_auc: 0.9737\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1610 - auc: 0.9828 - val_loss: 0.2074 - val_auc: 0.9732\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1694 - auc: 0.9810 - val_loss: 0.2075 - val_auc: 0.9731\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1632 - auc: 0.9825 - val_loss: 0.2073 - val_auc: 0.9732\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1664 - auc: 0.9815 - val_loss: 0.2070 - val_auc: 0.9732\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1644 - auc: 0.9824 - val_loss: 0.2068 - val_auc: 0.9732\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1684 - auc: 0.9813 - val_loss: 0.2067 - val_auc: 0.9731\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1588 - auc: 0.9836 - val_loss: 0.2066 - val_auc: 0.9731\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1703 - auc: 0.9817 - val_loss: 0.2064 - val_auc: 0.9731\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1671 - auc: 0.9819 - val_loss: 0.2065 - val_auc: 0.9731\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1586 - auc: 0.9835 - val_loss: 0.2066 - val_auc: 0.9732\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1696 - auc: 0.9809 - val_loss: 0.2067 - val_auc: 0.9732\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1590 - auc: 0.9839 - val_loss: 0.2067 - val_auc: 0.9732\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1654 - auc: 0.9821 - val_loss: 0.2067 - val_auc: 0.9732\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1620 - auc: 0.9830 - val_loss: 0.2067 - val_auc: 0.9733\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1608 - auc: 0.9831 - val_loss: 0.2066 - val_auc: 0.9733\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1556 - auc: 0.9842 - val_loss: 0.2065 - val_auc: 0.9733\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1579 - auc: 0.9840 - val_loss: 0.2064 - val_auc: 0.9734\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1518 - auc: 0.9851 - val_loss: 0.2063 - val_auc: 0.9733\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1607 - auc: 0.9835 - val_loss: 0.2061 - val_auc: 0.9733\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1602 - auc: 0.9832 - val_loss: 0.2060 - val_auc: 0.9732\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1624 - auc: 0.9830 - val_loss: 0.2057 - val_auc: 0.9733\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1646 - auc: 0.9827 - val_loss: 0.2055 - val_auc: 0.9732\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1683 - auc: 0.9814 - val_loss: 0.2055 - val_auc: 0.9733\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1582 - auc: 0.9842 - val_loss: 0.2055 - val_auc: 0.9734\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1579 - auc: 0.9832 - val_loss: 0.2054 - val_auc: 0.9734\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1621 - auc: 0.9830 - val_loss: 0.2052 - val_auc: 0.9733\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1620 - auc: 0.9832 - val_loss: 0.2051 - val_auc: 0.9733\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1565 - auc: 0.9842 - val_loss: 0.2050 - val_auc: 0.9734\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1646 - auc: 0.9822 - val_loss: 0.2048 - val_auc: 0.9734\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1615 - auc: 0.9826 - val_loss: 0.2045 - val_auc: 0.9734\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1628 - auc: 0.9823 - val_loss: 0.2043 - val_auc: 0.9734\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1613 - auc: 0.9827 - val_loss: 0.2041 - val_auc: 0.9734\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1563 - auc: 0.9837 - val_loss: 0.2041 - val_auc: 0.9735\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1618 - auc: 0.9828 - val_loss: 0.2041 - val_auc: 0.9735\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1577 - auc: 0.9837 - val_loss: 0.2042 - val_auc: 0.9735\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1581 - auc: 0.9838 - val_loss: 0.2039 - val_auc: 0.9735\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1602 - auc: 0.9834 - val_loss: 0.2037 - val_auc: 0.9735\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1638 - auc: 0.9827 - val_loss: 0.2037 - val_auc: 0.9736\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1541 - auc: 0.9847 - val_loss: 0.2039 - val_auc: 0.9736\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1657 - auc: 0.9825 - val_loss: 0.2039 - val_auc: 0.9736\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1566 - auc: 0.9842 - val_loss: 0.2040 - val_auc: 0.9730\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1675 - auc: 0.9814 - val_loss: 0.2041 - val_auc: 0.9730\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1630 - auc: 0.9826 - val_loss: 0.2040 - val_auc: 0.9731\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1572 - auc: 0.9841 - val_loss: 0.2041 - val_auc: 0.9730\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1604 - auc: 0.9829 - val_loss: 0.2041 - val_auc: 0.9731\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1661 - auc: 0.9823 - val_loss: 0.2039 - val_auc: 0.9736\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1535 - auc: 0.9845 - val_loss: 0.2035 - val_auc: 0.9736\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1592 - auc: 0.9830 - val_loss: 0.2031 - val_auc: 0.9736\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1581 - auc: 0.9838 - val_loss: 0.2026 - val_auc: 0.9736\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1553 - auc: 0.9841 - val_loss: 0.2025 - val_auc: 0.9736\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1631 - auc: 0.9826 - val_loss: 0.2026 - val_auc: 0.9735\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1590 - auc: 0.9830 - val_loss: 0.2028 - val_auc: 0.9736\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1598 - auc: 0.9831 - val_loss: 0.2029 - val_auc: 0.9735\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1592 - auc: 0.9834 - val_loss: 0.2032 - val_auc: 0.9736\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1579 - auc: 0.9841 - val_loss: 0.2035 - val_auc: 0.9730\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1539 - auc: 0.9849 - val_loss: 0.2034 - val_auc: 0.9730\n",
      "Epoch 359/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1553 - auc: 0.9843 - val_loss: 0.2034 - val_auc: 0.9730\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1571 - auc: 0.9834 - val_loss: 0.2032 - val_auc: 0.9730\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1566 - auc: 0.9842 - val_loss: 0.2027 - val_auc: 0.9737\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1559 - auc: 0.9839 - val_loss: 0.2025 - val_auc: 0.9736\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1654 - auc: 0.9829 - val_loss: 0.2024 - val_auc: 0.9736\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1591 - auc: 0.9836 - val_loss: 0.2022 - val_auc: 0.9735\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1638 - auc: 0.9827 - val_loss: 0.2023 - val_auc: 0.9735\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1548 - auc: 0.9844 - val_loss: 0.2022 - val_auc: 0.9736\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1543 - auc: 0.9844 - val_loss: 0.2019 - val_auc: 0.9736\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1565 - auc: 0.9839 - val_loss: 0.2017 - val_auc: 0.9736\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1553 - auc: 0.9842 - val_loss: 0.2015 - val_auc: 0.9731\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1534 - auc: 0.9846 - val_loss: 0.2013 - val_auc: 0.9731\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1598 - auc: 0.9835 - val_loss: 0.2013 - val_auc: 0.9733\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1571 - auc: 0.9837 - val_loss: 0.2013 - val_auc: 0.9733\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1543 - auc: 0.9844 - val_loss: 0.2012 - val_auc: 0.9733\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1625 - auc: 0.9824 - val_loss: 0.2010 - val_auc: 0.9733\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1559 - auc: 0.9842 - val_loss: 0.2006 - val_auc: 0.9734\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1597 - auc: 0.9834 - val_loss: 0.2006 - val_auc: 0.9734\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1616 - auc: 0.9828 - val_loss: 0.2007 - val_auc: 0.9733\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1578 - auc: 0.9835 - val_loss: 0.2008 - val_auc: 0.9734\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1564 - auc: 0.9838 - val_loss: 0.2008 - val_auc: 0.9733\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1592 - auc: 0.9831 - val_loss: 0.2006 - val_auc: 0.9734\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1530 - auc: 0.9850 - val_loss: 0.2007 - val_auc: 0.9734\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1463 - auc: 0.9861 - val_loss: 0.2009 - val_auc: 0.9733\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1546 - auc: 0.9847 - val_loss: 0.2012 - val_auc: 0.9728\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1564 - auc: 0.9835 - val_loss: 0.2013 - val_auc: 0.9728\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1581 - auc: 0.9840 - val_loss: 0.2013 - val_auc: 0.9728\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1565 - auc: 0.9839 - val_loss: 0.2014 - val_auc: 0.9728\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1524 - auc: 0.9850 - val_loss: 0.2015 - val_auc: 0.9729\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1597 - auc: 0.9834 - val_loss: 0.2016 - val_auc: 0.9729\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1513 - auc: 0.9852 - val_loss: 0.2018 - val_auc: 0.9728\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1581 - auc: 0.9833 - val_loss: 0.2019 - val_auc: 0.9729\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1541 - auc: 0.9844 - val_loss: 0.2020 - val_auc: 0.9729\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1569 - auc: 0.9841 - val_loss: 0.2019 - val_auc: 0.9728\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1567 - auc: 0.9837 - val_loss: 0.2016 - val_auc: 0.9728\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1563 - auc: 0.9836 - val_loss: 0.2011 - val_auc: 0.9727\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1603 - auc: 0.9833 - val_loss: 0.2010 - val_auc: 0.9727\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1612 - auc: 0.9834 - val_loss: 0.2011 - val_auc: 0.9726\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1516 - auc: 0.9846 - val_loss: 0.2012 - val_auc: 0.9726\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1614 - auc: 0.9827 - val_loss: 0.2011 - val_auc: 0.9726\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1505 - auc: 0.9851 - val_loss: 0.2011 - val_auc: 0.9727\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1542 - auc: 0.9850 - val_loss: 0.2010 - val_auc: 0.9727\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1600 - auc: 0.9836 - val_loss: 0.2010 - val_auc: 0.9727\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1551 - auc: 0.9845 - val_loss: 0.2012 - val_auc: 0.9728\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1478 - auc: 0.9856 - val_loss: 0.2012 - val_auc: 0.9726\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1528 - auc: 0.9846 - val_loss: 0.2013 - val_auc: 0.9726\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1583 - auc: 0.9829 - val_loss: 0.2013 - val_auc: 0.9725\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1577 - auc: 0.9836 - val_loss: 0.2013 - val_auc: 0.9727\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1552 - auc: 0.9841 - val_loss: 0.2010 - val_auc: 0.9731\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1464 - auc: 0.9861 - val_loss: 0.2010 - val_auc: 0.9731\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1567 - auc: 0.9843 - val_loss: 0.2010 - val_auc: 0.9731\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1560 - auc: 0.9844 - val_loss: 0.2011 - val_auc: 0.9731\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1484 - auc: 0.9858 - val_loss: 0.2012 - val_auc: 0.9732\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1554 - auc: 0.9842 - val_loss: 0.2011 - val_auc: 0.9732\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1523 - auc: 0.9849 - val_loss: 0.2010 - val_auc: 0.9733\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1505 - auc: 0.9855 - val_loss: 0.2010 - val_auc: 0.9733\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1465 - auc: 0.9859 - val_loss: 0.2010 - val_auc: 0.9733\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1538 - auc: 0.9848 - val_loss: 0.2009 - val_auc: 0.9733\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1530 - auc: 0.9847 - val_loss: 0.2008 - val_auc: 0.9733\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1551 - auc: 0.9842 - val_loss: 0.2006 - val_auc: 0.9734\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1494 - auc: 0.9852 - val_loss: 0.2003 - val_auc: 0.9735\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1538 - auc: 0.9845 - val_loss: 0.2002 - val_auc: 0.9735\n",
      "Epoch 421/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1583 - auc: 0.9834 - val_loss: 0.2002 - val_auc: 0.9734\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1496 - auc: 0.9854 - val_loss: 0.2004 - val_auc: 0.9734\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1429 - auc: 0.9864 - val_loss: 0.2003 - val_auc: 0.9734\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1498 - auc: 0.9855 - val_loss: 0.2001 - val_auc: 0.9734\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1492 - auc: 0.9853 - val_loss: 0.2001 - val_auc: 0.9734\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1505 - auc: 0.9854 - val_loss: 0.2001 - val_auc: 0.9735\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1505 - auc: 0.9852 - val_loss: 0.2003 - val_auc: 0.9735\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1548 - auc: 0.9844 - val_loss: 0.2007 - val_auc: 0.9734\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1538 - auc: 0.9842 - val_loss: 0.2009 - val_auc: 0.9734\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1535 - auc: 0.9849 - val_loss: 0.2007 - val_auc: 0.9734\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1479 - auc: 0.9857 - val_loss: 0.2007 - val_auc: 0.9728\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1467 - auc: 0.9859 - val_loss: 0.2008 - val_auc: 0.9728\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1533 - auc: 0.9846 - val_loss: 0.2010 - val_auc: 0.9727\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1467 - auc: 0.9855 - val_loss: 0.2011 - val_auc: 0.9728\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1529 - auc: 0.9849 - val_loss: 0.2011 - val_auc: 0.9727\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1542 - auc: 0.9843 - val_loss: 0.2011 - val_auc: 0.9728\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1552 - auc: 0.9843 - val_loss: 0.2010 - val_auc: 0.9728\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1508 - auc: 0.9852 - val_loss: 0.2008 - val_auc: 0.9728\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1499 - auc: 0.9852 - val_loss: 0.2007 - val_auc: 0.9728\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1492 - auc: 0.9852 - val_loss: 0.2005 - val_auc: 0.9728\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1450 - auc: 0.9859 - val_loss: 0.2004 - val_auc: 0.9729\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1585 - auc: 0.9832 - val_loss: 0.2003 - val_auc: 0.9729\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1576 - auc: 0.9842 - val_loss: 0.2002 - val_auc: 0.9729\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1416 - auc: 0.9874 - val_loss: 0.2000 - val_auc: 0.9729\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1463 - auc: 0.9860 - val_loss: 0.2001 - val_auc: 0.9730\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1554 - auc: 0.9847 - val_loss: 0.2003 - val_auc: 0.9729\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1585 - auc: 0.9831 - val_loss: 0.2002 - val_auc: 0.9729\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1519 - auc: 0.9852 - val_loss: 0.2002 - val_auc: 0.9729\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1565 - auc: 0.9844 - val_loss: 0.2001 - val_auc: 0.9730\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1436 - auc: 0.9866 - val_loss: 0.2000 - val_auc: 0.9730\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1416 - auc: 0.9870 - val_loss: 0.2000 - val_auc: 0.9731\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1536 - auc: 0.9846 - val_loss: 0.2001 - val_auc: 0.9729\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1480 - auc: 0.9853 - val_loss: 0.2000 - val_auc: 0.9729\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1536 - auc: 0.9846 - val_loss: 0.1996 - val_auc: 0.9731\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1514 - auc: 0.9854 - val_loss: 0.1995 - val_auc: 0.9731\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1490 - auc: 0.9854 - val_loss: 0.1996 - val_auc: 0.9729\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1548 - auc: 0.9844 - val_loss: 0.1996 - val_auc: 0.9729\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1503 - auc: 0.9853 - val_loss: 0.1997 - val_auc: 0.9735\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1494 - auc: 0.9854 - val_loss: 0.1999 - val_auc: 0.9735\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1467 - auc: 0.9858 - val_loss: 0.2001 - val_auc: 0.9736\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1547 - auc: 0.9838 - val_loss: 0.2000 - val_auc: 0.9737\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1496 - auc: 0.9852 - val_loss: 0.1997 - val_auc: 0.9738\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1496 - auc: 0.9854 - val_loss: 0.1994 - val_auc: 0.9738\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1533 - auc: 0.9850 - val_loss: 0.1990 - val_auc: 0.9739\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1440 - auc: 0.9867 - val_loss: 0.1987 - val_auc: 0.9739\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1451 - auc: 0.9860 - val_loss: 0.1983 - val_auc: 0.9740\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1427 - auc: 0.9869 - val_loss: 0.1980 - val_auc: 0.9739\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1514 - auc: 0.9845 - val_loss: 0.1980 - val_auc: 0.9741\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1530 - auc: 0.9841 - val_loss: 0.1981 - val_auc: 0.9741\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1505 - auc: 0.9850 - val_loss: 0.1983 - val_auc: 0.9740\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1456 - auc: 0.9863 - val_loss: 0.1981 - val_auc: 0.9741\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1447 - auc: 0.9863 - val_loss: 0.1979 - val_auc: 0.9741\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1550 - auc: 0.9843 - val_loss: 0.1979 - val_auc: 0.9741\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1482 - auc: 0.9860 - val_loss: 0.1980 - val_auc: 0.9739\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1462 - auc: 0.9856 - val_loss: 0.1979 - val_auc: 0.9740\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1475 - auc: 0.9858 - val_loss: 0.1979 - val_auc: 0.9740\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1532 - auc: 0.9847 - val_loss: 0.1974 - val_auc: 0.9741\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1437 - auc: 0.9865 - val_loss: 0.1972 - val_auc: 0.9742\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1519 - auc: 0.9845 - val_loss: 0.1970 - val_auc: 0.9742\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1513 - auc: 0.9849 - val_loss: 0.1972 - val_auc: 0.9742\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1470 - auc: 0.9858 - val_loss: 0.1976 - val_auc: 0.9741\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1422 - auc: 0.9869 - val_loss: 0.1979 - val_auc: 0.9740\n",
      "Epoch 483/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1528 - auc: 0.9846 - val_loss: 0.1983 - val_auc: 0.9740\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1459 - auc: 0.9860 - val_loss: 0.1985 - val_auc: 0.9739\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1488 - auc: 0.9856 - val_loss: 0.1988 - val_auc: 0.9739\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1525 - auc: 0.9847 - val_loss: 0.1990 - val_auc: 0.9739\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1458 - auc: 0.9860 - val_loss: 0.1990 - val_auc: 0.9738\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1490 - auc: 0.9850 - val_loss: 0.1986 - val_auc: 0.9738\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1437 - auc: 0.9863 - val_loss: 0.1985 - val_auc: 0.9739\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1510 - auc: 0.9850 - val_loss: 0.1986 - val_auc: 0.9738\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1473 - auc: 0.9859 - val_loss: 0.1988 - val_auc: 0.9738\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1532 - auc: 0.9844 - val_loss: 0.1991 - val_auc: 0.9739\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1505 - auc: 0.9850 - val_loss: 0.1992 - val_auc: 0.9739\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1502 - auc: 0.9856 - val_loss: 0.1992 - val_auc: 0.9739\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1507 - auc: 0.9851 - val_loss: 0.1991 - val_auc: 0.9739\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1478 - auc: 0.9859 - val_loss: 0.1990 - val_auc: 0.9739\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1428 - auc: 0.9864 - val_loss: 0.1990 - val_auc: 0.9740\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1488 - auc: 0.9856 - val_loss: 0.1988 - val_auc: 0.9740\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1542 - auc: 0.9845 - val_loss: 0.1989 - val_auc: 0.9739\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1395 - auc: 0.9872 - val_loss: 0.1990 - val_auc: 0.9739\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, \n",
    "          epochs=500, \n",
    "          batch_size=1000, \n",
    "          validation_data=(x_test, y_test),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38552162",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "Finding the co relation between features and with y label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efec3b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_make                0.227362\n",
      "word_freq_address             0.283375\n",
      "word_freq_all                 0.300356\n",
      "word_freq_3d                  0.090552\n",
      "word_freq_our                 0.371915\n",
      "word_freq_over                0.301855\n",
      "word_freq_remove              0.496535\n",
      "word_freq_internet            0.328766\n",
      "word_freq_order               0.288399\n",
      "word_freq_mail                0.276449\n",
      "word_freq_receive             0.341674\n",
      "word_freq_will                0.130913\n",
      "word_freq_people              0.203286\n",
      "word_freq_report              0.146933\n",
      "word_freq_addresses           0.260423\n",
      "word_freq_free                0.471148\n",
      "word_freq_business            0.334895\n",
      "word_freq_email               0.282620\n",
      "word_freq_you                 0.305032\n",
      "word_freq_credit              0.316879\n",
      "word_freq_your                0.439906\n",
      "word_freq_font                0.137109\n",
      "word_freq_000                 0.410411\n",
      "word_freq_money               0.453766\n",
      "word_freq_hp                  0.376617\n",
      "word_freq_hpl                 0.327062\n",
      "word_freq_george              0.339331\n",
      "word_freq_650                 0.220570\n",
      "word_freq_lab                 0.216288\n",
      "word_freq_labs                0.239628\n",
      "word_freq_telnet              0.201464\n",
      "word_freq_857                 0.167975\n",
      "word_freq_data                0.154144\n",
      "word_freq_415                 0.156210\n",
      "word_freq_85                  0.208572\n",
      "word_freq_technology          0.161467\n",
      "word_freq_1999                0.249198\n",
      "word_freq_parts               0.002514\n",
      "word_freq_pm                  0.144185\n",
      "word_freq_direct              0.027454\n",
      "word_freq_cs                  0.143391\n",
      "word_freq_meeting             0.192157\n",
      "word_freq_original            0.105657\n",
      "word_freq_project             0.142011\n",
      "word_freq_re                  0.066805\n",
      "word_freq_edu                 0.191568\n",
      "word_freq_table               0.022592\n",
      "word_freq_conference          0.137525\n",
      "char_freq_;                   0.054436\n",
      "char_freq_(                   0.028207\n",
      "char_freq_[                   0.108074\n",
      "char_freq_!                   0.528564\n",
      "char_freq_$                   0.523779\n",
      "char_freq_hash                0.255993\n",
      "capital_run_length_average    0.399748\n",
      "capital_run_length_longest    0.425838\n",
      "capital_run_length_total      0.363252\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Finding the co relation between each feature and label\n",
    "# As the features are numerical and label is categorical so kendall is used to measure cor relation \n",
    "x = spam_data.drop(\"spam\", axis = 1)\n",
    "corr_action=x.corrwith(spam_data['spam'],method='kendall').abs()\n",
    "print(corr_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "394373f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "asc_order=corr_action.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c68414a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "char_freq_!                   0.528564\n",
       "char_freq_$                   0.523779\n",
       "word_freq_remove              0.496535\n",
       "word_freq_free                0.471148\n",
       "word_freq_money               0.453766\n",
       "word_freq_your                0.439906\n",
       "capital_run_length_longest    0.425838\n",
       "word_freq_000                 0.410411\n",
       "capital_run_length_average    0.399748\n",
       "word_freq_hp                  0.376617\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asc_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b19eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_num_features=asc_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "570b4ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_num_features_col=relevant_num_features.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e7f806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_num_df = x[relevant_num_features_col]  # Only getting first 10 most correlated features w.r.t output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "123df937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   char_freq_!                 4601 non-null   float64\n",
      " 1   char_freq_$                 4601 non-null   float64\n",
      " 2   word_freq_remove            4601 non-null   float64\n",
      " 3   word_freq_free              4601 non-null   float64\n",
      " 4   word_freq_money             4601 non-null   float64\n",
      " 5   word_freq_your              4601 non-null   float64\n",
      " 6   capital_run_length_longest  4601 non-null   int64  \n",
      " 7   word_freq_000               4601 non-null   float64\n",
      " 8   capital_run_length_average  4601 non-null   float64\n",
      " 9   word_freq_hp                4601 non-null   float64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 359.6 KB\n"
     ]
    }
   ],
   "source": [
    "selected_num_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f4ee8f",
   "metadata": {},
   "source": [
    "# Part3\n",
    "Removing the significant features and building a fully connected classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f358c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_cols_list=relevant_num_features_col.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d59c17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['char_freq_!',\n",
       " 'char_freq_$',\n",
       " 'word_freq_remove',\n",
       " 'word_freq_free',\n",
       " 'word_freq_money',\n",
       " 'word_freq_your',\n",
       " 'capital_run_length_longest',\n",
       " 'word_freq_000',\n",
       " 'capital_run_length_average',\n",
       " 'word_freq_hp']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [\"char_freq_!\",\"char_freq_$\",\"word_freq_remove\",\"word_freq_free\",\"word_freq_money\",\"word_freq_your\",\n",
    "# \"capital_run_length_longest\",\"word_freq_000\",\"capital_run_length_average\",\"word_freq_hp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d4d00cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dropping at are highly significant i.e those features that have large impact on y \n",
    "# #splitting into X and y\n",
    "# X_1 = spam_data.drop([\"char_freq_!\",\"char_freq_$\",\"word_freq_remove\",\"word_freq_free\",\"word_freq_money\",\"word_freq_your\",\n",
    "# \"capital_run_length_longest\",\"word_freq_000\",\"capital_run_length_average\",\"word_freq_hp\",\"spam\"], axis = 1)\n",
    "# y_1 =spam_data.spam.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f142d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = spam_data.drop(rel_cols_list, axis = 1)\n",
    "y_1 =spam_data.spam.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abfc5708",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = scale(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50b96ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "x_train_1,x_test_1, y_train_1, y_test_1 = train_test_split(x_1, y_1, test_size = 0.3, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "025348b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the model architecture\n",
    "#A dropout layer is inserted  as a form of regularization \n",
    "#which will help reduce overfitting by randomly setting (here 30%) of the input unit values to zero.\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=9, activation=\"relu\", input_shape=(x_train_1.shape[-1],) ),\n",
    "        # randomly delete 30% of the input units below\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(units=9, activation=\"relu\"),\n",
    "        # the output layer, with a single neuron\n",
    "        keras.layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# save the initial weights for later\n",
    "initial_weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "809dc72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "              loss=\"binary_crossentropy\", \n",
    "              metrics=keras.metrics.AUC())\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e90ef331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f045c67fc20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f045c67fc20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/4 [======>.......................] - ETA: 1s - loss: 0.6937 - auc_1: 0.5650WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f0485d837a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f0485d837a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4/4 [==============================] - 1s 102ms/step - loss: 0.6866 - auc_1: 0.5575 - val_loss: 0.6622 - val_auc_1: 0.5816\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6827 - auc_1: 0.5663 - val_loss: 0.6495 - val_auc_1: 0.6120\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6662 - auc_1: 0.6003 - val_loss: 0.6373 - val_auc_1: 0.6419\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6571 - auc_1: 0.6262 - val_loss: 0.6258 - val_auc_1: 0.6716\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6407 - auc_1: 0.6458 - val_loss: 0.6151 - val_auc_1: 0.7046\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6348 - auc_1: 0.6734 - val_loss: 0.6047 - val_auc_1: 0.7348\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6305 - auc_1: 0.6855 - val_loss: 0.5949 - val_auc_1: 0.7576\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6149 - auc_1: 0.7167 - val_loss: 0.5857 - val_auc_1: 0.7773\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6173 - auc_1: 0.7146 - val_loss: 0.5771 - val_auc_1: 0.7968\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6058 - auc_1: 0.7388 - val_loss: 0.5693 - val_auc_1: 0.8111\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5930 - auc_1: 0.7616 - val_loss: 0.5617 - val_auc_1: 0.8238\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5890 - auc_1: 0.7652 - val_loss: 0.5541 - val_auc_1: 0.8340\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5847 - auc_1: 0.7712 - val_loss: 0.5466 - val_auc_1: 0.8433\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5776 - auc_1: 0.7895 - val_loss: 0.5391 - val_auc_1: 0.8519\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5673 - auc_1: 0.8010 - val_loss: 0.5315 - val_auc_1: 0.8594\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5562 - auc_1: 0.8121 - val_loss: 0.5241 - val_auc_1: 0.8654\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5545 - auc_1: 0.8162 - val_loss: 0.5165 - val_auc_1: 0.8710\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5485 - auc_1: 0.8231 - val_loss: 0.5090 - val_auc_1: 0.8757\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5376 - auc_1: 0.8273 - val_loss: 0.5017 - val_auc_1: 0.8802\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5234 - auc_1: 0.8455 - val_loss: 0.4944 - val_auc_1: 0.8842\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5214 - auc_1: 0.8435 - val_loss: 0.4872 - val_auc_1: 0.8881\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5174 - auc_1: 0.8451 - val_loss: 0.4802 - val_auc_1: 0.8915\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5149 - auc_1: 0.8449 - val_loss: 0.4734 - val_auc_1: 0.8941\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5043 - auc_1: 0.8538 - val_loss: 0.4667 - val_auc_1: 0.8964\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5036 - auc_1: 0.8527 - val_loss: 0.4602 - val_auc_1: 0.8991\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4974 - auc_1: 0.8544 - val_loss: 0.4540 - val_auc_1: 0.9012\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4886 - auc_1: 0.8597 - val_loss: 0.4479 - val_auc_1: 0.9035\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4792 - auc_1: 0.8656 - val_loss: 0.4420 - val_auc_1: 0.9053\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4822 - auc_1: 0.8666 - val_loss: 0.4363 - val_auc_1: 0.9067\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4720 - auc_1: 0.8695 - val_loss: 0.4309 - val_auc_1: 0.9083\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4706 - auc_1: 0.8690 - val_loss: 0.4258 - val_auc_1: 0.9097\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4649 - auc_1: 0.8733 - val_loss: 0.4211 - val_auc_1: 0.9109\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4598 - auc_1: 0.8758 - val_loss: 0.4166 - val_auc_1: 0.9121\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4601 - auc_1: 0.8751 - val_loss: 0.4125 - val_auc_1: 0.9135\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4562 - auc_1: 0.8735 - val_loss: 0.4085 - val_auc_1: 0.9142\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4496 - auc_1: 0.8808 - val_loss: 0.4047 - val_auc_1: 0.9153\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4505 - auc_1: 0.8762 - val_loss: 0.4009 - val_auc_1: 0.9160\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4408 - auc_1: 0.8818 - val_loss: 0.3973 - val_auc_1: 0.9169\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4461 - auc_1: 0.8794 - val_loss: 0.3937 - val_auc_1: 0.9179\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4361 - auc_1: 0.8824 - val_loss: 0.3903 - val_auc_1: 0.9188\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4328 - auc_1: 0.8888 - val_loss: 0.3870 - val_auc_1: 0.9197\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4342 - auc_1: 0.8848 - val_loss: 0.3840 - val_auc_1: 0.9203\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4357 - auc_1: 0.8890 - val_loss: 0.3811 - val_auc_1: 0.9211\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4179 - auc_1: 0.8967 - val_loss: 0.3782 - val_auc_1: 0.9218\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4176 - auc_1: 0.8940 - val_loss: 0.3754 - val_auc_1: 0.9225\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4199 - auc_1: 0.8919 - val_loss: 0.3727 - val_auc_1: 0.9230\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4170 - auc_1: 0.8941 - val_loss: 0.3704 - val_auc_1: 0.9237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4175 - auc_1: 0.8925 - val_loss: 0.3680 - val_auc_1: 0.9243\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4121 - auc_1: 0.8943 - val_loss: 0.3658 - val_auc_1: 0.9251\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4134 - auc_1: 0.8925 - val_loss: 0.3636 - val_auc_1: 0.9257\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4036 - auc_1: 0.8996 - val_loss: 0.3617 - val_auc_1: 0.9265\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4117 - auc_1: 0.8945 - val_loss: 0.3598 - val_auc_1: 0.9269\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4011 - auc_1: 0.9017 - val_loss: 0.3579 - val_auc_1: 0.9275\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4011 - auc_1: 0.9024 - val_loss: 0.3561 - val_auc_1: 0.9281\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3953 - auc_1: 0.9041 - val_loss: 0.3543 - val_auc_1: 0.9286\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4042 - auc_1: 0.8969 - val_loss: 0.3527 - val_auc_1: 0.9292\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3934 - auc_1: 0.9052 - val_loss: 0.3511 - val_auc_1: 0.9296\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3919 - auc_1: 0.9073 - val_loss: 0.3496 - val_auc_1: 0.9302\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3917 - auc_1: 0.9054 - val_loss: 0.3482 - val_auc_1: 0.9306\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3953 - auc_1: 0.9037 - val_loss: 0.3467 - val_auc_1: 0.9310\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3790 - auc_1: 0.9123 - val_loss: 0.3451 - val_auc_1: 0.9315\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3975 - auc_1: 0.9028 - val_loss: 0.3437 - val_auc_1: 0.9317\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3788 - auc_1: 0.9131 - val_loss: 0.3423 - val_auc_1: 0.9323\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3880 - auc_1: 0.9082 - val_loss: 0.3410 - val_auc_1: 0.9326\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3826 - auc_1: 0.9101 - val_loss: 0.3398 - val_auc_1: 0.9331\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3780 - auc_1: 0.9110 - val_loss: 0.3386 - val_auc_1: 0.9333\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3734 - auc_1: 0.9155 - val_loss: 0.3374 - val_auc_1: 0.9337\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3764 - auc_1: 0.9117 - val_loss: 0.3363 - val_auc_1: 0.9341\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3731 - auc_1: 0.9131 - val_loss: 0.3353 - val_auc_1: 0.9346\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3770 - auc_1: 0.9123 - val_loss: 0.3342 - val_auc_1: 0.9350\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3768 - auc_1: 0.9134 - val_loss: 0.3333 - val_auc_1: 0.9354\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3772 - auc_1: 0.9111 - val_loss: 0.3323 - val_auc_1: 0.9357\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3647 - auc_1: 0.9189 - val_loss: 0.3313 - val_auc_1: 0.9361\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3724 - auc_1: 0.9131 - val_loss: 0.3303 - val_auc_1: 0.9364\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3718 - auc_1: 0.9177 - val_loss: 0.3294 - val_auc_1: 0.9369\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3631 - auc_1: 0.9197 - val_loss: 0.3284 - val_auc_1: 0.9371\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3563 - auc_1: 0.9236 - val_loss: 0.3275 - val_auc_1: 0.9374\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3555 - auc_1: 0.9239 - val_loss: 0.3265 - val_auc_1: 0.9378\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3594 - auc_1: 0.9218 - val_loss: 0.3255 - val_auc_1: 0.9380\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3676 - auc_1: 0.9168 - val_loss: 0.3245 - val_auc_1: 0.9384\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3642 - auc_1: 0.9191 - val_loss: 0.3235 - val_auc_1: 0.9386\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3585 - auc_1: 0.9230 - val_loss: 0.3225 - val_auc_1: 0.9391\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3550 - auc_1: 0.9233 - val_loss: 0.3216 - val_auc_1: 0.9393\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3596 - auc_1: 0.9207 - val_loss: 0.3207 - val_auc_1: 0.9396\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3619 - auc_1: 0.9200 - val_loss: 0.3198 - val_auc_1: 0.9399\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3594 - auc_1: 0.9212 - val_loss: 0.3190 - val_auc_1: 0.9401\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3418 - auc_1: 0.9290 - val_loss: 0.3183 - val_auc_1: 0.9404\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3515 - auc_1: 0.9235 - val_loss: 0.3176 - val_auc_1: 0.9407\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3495 - auc_1: 0.9263 - val_loss: 0.3168 - val_auc_1: 0.9408\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3523 - auc_1: 0.9257 - val_loss: 0.3161 - val_auc_1: 0.9406\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3523 - auc_1: 0.9247 - val_loss: 0.3153 - val_auc_1: 0.9407\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3478 - auc_1: 0.9254 - val_loss: 0.3146 - val_auc_1: 0.9410\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3501 - auc_1: 0.9243 - val_loss: 0.3139 - val_auc_1: 0.9412\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3372 - auc_1: 0.9317 - val_loss: 0.3133 - val_auc_1: 0.9413\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3387 - auc_1: 0.9286 - val_loss: 0.3126 - val_auc_1: 0.9414\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3441 - auc_1: 0.9268 - val_loss: 0.3120 - val_auc_1: 0.9416\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3373 - auc_1: 0.9319 - val_loss: 0.3114 - val_auc_1: 0.9418\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3363 - auc_1: 0.9303 - val_loss: 0.3109 - val_auc_1: 0.9421\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3398 - auc_1: 0.9310 - val_loss: 0.3102 - val_auc_1: 0.9422\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3346 - auc_1: 0.9308 - val_loss: 0.3097 - val_auc_1: 0.9423\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3296 - auc_1: 0.9349 - val_loss: 0.3090 - val_auc_1: 0.9425\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3361 - auc_1: 0.9304 - val_loss: 0.3083 - val_auc_1: 0.9428\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3328 - auc_1: 0.9326 - val_loss: 0.3076 - val_auc_1: 0.9429\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3412 - auc_1: 0.9290 - val_loss: 0.3069 - val_auc_1: 0.9431\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3361 - auc_1: 0.9292 - val_loss: 0.3063 - val_auc_1: 0.9433\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3302 - auc_1: 0.9335 - val_loss: 0.3058 - val_auc_1: 0.9435\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3338 - auc_1: 0.9317 - val_loss: 0.3053 - val_auc_1: 0.9441\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3244 - auc_1: 0.9360 - val_loss: 0.3048 - val_auc_1: 0.9443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3352 - auc_1: 0.9312 - val_loss: 0.3043 - val_auc_1: 0.9446\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3238 - auc_1: 0.9360 - val_loss: 0.3039 - val_auc_1: 0.9448\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3269 - auc_1: 0.9343 - val_loss: 0.3033 - val_auc_1: 0.9450\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3270 - auc_1: 0.9345 - val_loss: 0.3027 - val_auc_1: 0.9451\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3220 - auc_1: 0.9374 - val_loss: 0.3021 - val_auc_1: 0.9454\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3229 - auc_1: 0.9359 - val_loss: 0.3013 - val_auc_1: 0.9456\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3340 - auc_1: 0.9315 - val_loss: 0.3007 - val_auc_1: 0.9458\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3250 - auc_1: 0.9342 - val_loss: 0.3002 - val_auc_1: 0.9461\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3249 - auc_1: 0.9359 - val_loss: 0.2998 - val_auc_1: 0.9463\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3172 - auc_1: 0.9387 - val_loss: 0.2994 - val_auc_1: 0.9465\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3236 - auc_1: 0.9357 - val_loss: 0.2989 - val_auc_1: 0.9466\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3236 - auc_1: 0.9342 - val_loss: 0.2984 - val_auc_1: 0.9468\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3159 - auc_1: 0.9390 - val_loss: 0.2979 - val_auc_1: 0.9472\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3134 - auc_1: 0.9413 - val_loss: 0.2974 - val_auc_1: 0.9473\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3167 - auc_1: 0.9394 - val_loss: 0.2969 - val_auc_1: 0.9475\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3181 - auc_1: 0.9375 - val_loss: 0.2964 - val_auc_1: 0.9478\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3136 - auc_1: 0.9396 - val_loss: 0.2959 - val_auc_1: 0.9479\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3131 - auc_1: 0.9406 - val_loss: 0.2955 - val_auc_1: 0.9482\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3124 - auc_1: 0.9395 - val_loss: 0.2951 - val_auc_1: 0.9484\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3043 - auc_1: 0.9439 - val_loss: 0.2947 - val_auc_1: 0.9485\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3125 - auc_1: 0.9403 - val_loss: 0.2944 - val_auc_1: 0.9486\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3139 - auc_1: 0.9401 - val_loss: 0.2942 - val_auc_1: 0.9488\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3093 - auc_1: 0.9411 - val_loss: 0.2941 - val_auc_1: 0.9490\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3122 - auc_1: 0.9411 - val_loss: 0.2941 - val_auc_1: 0.9490\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3159 - auc_1: 0.9391 - val_loss: 0.2942 - val_auc_1: 0.9489\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3098 - auc_1: 0.9410 - val_loss: 0.2941 - val_auc_1: 0.9489\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3042 - auc_1: 0.9450 - val_loss: 0.2938 - val_auc_1: 0.9490\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3090 - auc_1: 0.9412 - val_loss: 0.2937 - val_auc_1: 0.9490\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3113 - auc_1: 0.9393 - val_loss: 0.2936 - val_auc_1: 0.9492\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3092 - auc_1: 0.9408 - val_loss: 0.2937 - val_auc_1: 0.9493\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3156 - auc_1: 0.9376 - val_loss: 0.2936 - val_auc_1: 0.9493\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3079 - auc_1: 0.9415 - val_loss: 0.2934 - val_auc_1: 0.9496\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3080 - auc_1: 0.9409 - val_loss: 0.2931 - val_auc_1: 0.9497\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3043 - auc_1: 0.9435 - val_loss: 0.2929 - val_auc_1: 0.9495\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3104 - auc_1: 0.9417 - val_loss: 0.2927 - val_auc_1: 0.9495\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3103 - auc_1: 0.9413 - val_loss: 0.2926 - val_auc_1: 0.9496\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3012 - auc_1: 0.9451 - val_loss: 0.2923 - val_auc_1: 0.9498\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3040 - auc_1: 0.9429 - val_loss: 0.2920 - val_auc_1: 0.9499\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3111 - auc_1: 0.9409 - val_loss: 0.2917 - val_auc_1: 0.9500\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2995 - auc_1: 0.9442 - val_loss: 0.2915 - val_auc_1: 0.9495\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2996 - auc_1: 0.9442 - val_loss: 0.2914 - val_auc_1: 0.9495\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2977 - auc_1: 0.9456 - val_loss: 0.2914 - val_auc_1: 0.9495\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3004 - auc_1: 0.9456 - val_loss: 0.2912 - val_auc_1: 0.9497\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2960 - auc_1: 0.9460 - val_loss: 0.2909 - val_auc_1: 0.9496\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2996 - auc_1: 0.9444 - val_loss: 0.2907 - val_auc_1: 0.9497\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3026 - auc_1: 0.9438 - val_loss: 0.2906 - val_auc_1: 0.9498\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3026 - auc_1: 0.9440 - val_loss: 0.2905 - val_auc_1: 0.9498\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2964 - auc_1: 0.9451 - val_loss: 0.2905 - val_auc_1: 0.9499\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3031 - auc_1: 0.9424 - val_loss: 0.2905 - val_auc_1: 0.9498\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2987 - auc_1: 0.9438 - val_loss: 0.2905 - val_auc_1: 0.9498\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2952 - auc_1: 0.9464 - val_loss: 0.2904 - val_auc_1: 0.9497\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2905 - auc_1: 0.9490 - val_loss: 0.2902 - val_auc_1: 0.9498\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2887 - auc_1: 0.9484 - val_loss: 0.2901 - val_auc_1: 0.9498\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2898 - auc_1: 0.9475 - val_loss: 0.2902 - val_auc_1: 0.9497\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2943 - auc_1: 0.9470 - val_loss: 0.2902 - val_auc_1: 0.9498\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3074 - auc_1: 0.9422 - val_loss: 0.2903 - val_auc_1: 0.9497\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2969 - auc_1: 0.9468 - val_loss: 0.2901 - val_auc_1: 0.9498\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3001 - auc_1: 0.9448 - val_loss: 0.2899 - val_auc_1: 0.9499\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2938 - auc_1: 0.9459 - val_loss: 0.2897 - val_auc_1: 0.9499\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2873 - auc_1: 0.9499 - val_loss: 0.2896 - val_auc_1: 0.9499\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3017 - auc_1: 0.9428 - val_loss: 0.2896 - val_auc_1: 0.9498\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2894 - auc_1: 0.9481 - val_loss: 0.2895 - val_auc_1: 0.9499\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2994 - auc_1: 0.9439 - val_loss: 0.2894 - val_auc_1: 0.9500\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2946 - auc_1: 0.9465 - val_loss: 0.2893 - val_auc_1: 0.9501\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2956 - auc_1: 0.9462 - val_loss: 0.2889 - val_auc_1: 0.9503\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2884 - auc_1: 0.9474 - val_loss: 0.2886 - val_auc_1: 0.9504\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2865 - auc_1: 0.9496 - val_loss: 0.2884 - val_auc_1: 0.9505\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2919 - auc_1: 0.9481 - val_loss: 0.2882 - val_auc_1: 0.9506\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2912 - auc_1: 0.9471 - val_loss: 0.2881 - val_auc_1: 0.9506\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2884 - auc_1: 0.9480 - val_loss: 0.2880 - val_auc_1: 0.9507\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2935 - auc_1: 0.9463 - val_loss: 0.2879 - val_auc_1: 0.9508\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2892 - auc_1: 0.9483 - val_loss: 0.2878 - val_auc_1: 0.9510\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2909 - auc_1: 0.9482 - val_loss: 0.2877 - val_auc_1: 0.9510\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2907 - auc_1: 0.9481 - val_loss: 0.2877 - val_auc_1: 0.9509\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2782 - auc_1: 0.9519 - val_loss: 0.2877 - val_auc_1: 0.9510\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2889 - auc_1: 0.9478 - val_loss: 0.2879 - val_auc_1: 0.9510\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2844 - auc_1: 0.9496 - val_loss: 0.2882 - val_auc_1: 0.9510\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2839 - auc_1: 0.9492 - val_loss: 0.2883 - val_auc_1: 0.9509\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2894 - auc_1: 0.9487 - val_loss: 0.2885 - val_auc_1: 0.9508\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2840 - auc_1: 0.9502 - val_loss: 0.2886 - val_auc_1: 0.9508\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2827 - auc_1: 0.9513 - val_loss: 0.2887 - val_auc_1: 0.9507\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2802 - auc_1: 0.9510 - val_loss: 0.2884 - val_auc_1: 0.9507\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2863 - auc_1: 0.9493 - val_loss: 0.2881 - val_auc_1: 0.9508\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2783 - auc_1: 0.9527 - val_loss: 0.2874 - val_auc_1: 0.9509\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2881 - auc_1: 0.9483 - val_loss: 0.2868 - val_auc_1: 0.9511\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2863 - auc_1: 0.9502 - val_loss: 0.2863 - val_auc_1: 0.9518\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2830 - auc_1: 0.9505 - val_loss: 0.2861 - val_auc_1: 0.9519\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2765 - auc_1: 0.9533 - val_loss: 0.2861 - val_auc_1: 0.9520\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2848 - auc_1: 0.9492 - val_loss: 0.2860 - val_auc_1: 0.9520\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2835 - auc_1: 0.9507 - val_loss: 0.2858 - val_auc_1: 0.9521\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2836 - auc_1: 0.9509 - val_loss: 0.2854 - val_auc_1: 0.9518\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2802 - auc_1: 0.9514 - val_loss: 0.2849 - val_auc_1: 0.9520\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2864 - auc_1: 0.9488 - val_loss: 0.2846 - val_auc_1: 0.9521\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2833 - auc_1: 0.9496 - val_loss: 0.2844 - val_auc_1: 0.9520\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2795 - auc_1: 0.9516 - val_loss: 0.2843 - val_auc_1: 0.9521\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2729 - auc_1: 0.9536 - val_loss: 0.2842 - val_auc_1: 0.9521\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2764 - auc_1: 0.9520 - val_loss: 0.2842 - val_auc_1: 0.9521\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2711 - auc_1: 0.9539 - val_loss: 0.2841 - val_auc_1: 0.9521\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2767 - auc_1: 0.9523 - val_loss: 0.2838 - val_auc_1: 0.9518\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2764 - auc_1: 0.9528 - val_loss: 0.2837 - val_auc_1: 0.9518\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2777 - auc_1: 0.9519 - val_loss: 0.2838 - val_auc_1: 0.9520\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2677 - auc_1: 0.9549 - val_loss: 0.2840 - val_auc_1: 0.9520\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2755 - auc_1: 0.9537 - val_loss: 0.2840 - val_auc_1: 0.9521\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2781 - auc_1: 0.9519 - val_loss: 0.2839 - val_auc_1: 0.9521\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2801 - auc_1: 0.9517 - val_loss: 0.2838 - val_auc_1: 0.9522\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2804 - auc_1: 0.9495 - val_loss: 0.2837 - val_auc_1: 0.9522\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2711 - auc_1: 0.9542 - val_loss: 0.2837 - val_auc_1: 0.9523\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2708 - auc_1: 0.9544 - val_loss: 0.2836 - val_auc_1: 0.9523\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2755 - auc_1: 0.9523 - val_loss: 0.2835 - val_auc_1: 0.9524\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2798 - auc_1: 0.9507 - val_loss: 0.2835 - val_auc_1: 0.9525\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2775 - auc_1: 0.9523 - val_loss: 0.2834 - val_auc_1: 0.9525\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2667 - auc_1: 0.9558 - val_loss: 0.2832 - val_auc_1: 0.9526\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2721 - auc_1: 0.9538 - val_loss: 0.2831 - val_auc_1: 0.9527\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2741 - auc_1: 0.9536 - val_loss: 0.2830 - val_auc_1: 0.9528\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2656 - auc_1: 0.9567 - val_loss: 0.2828 - val_auc_1: 0.9528\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2698 - auc_1: 0.9542 - val_loss: 0.2824 - val_auc_1: 0.9529\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2638 - auc_1: 0.9563 - val_loss: 0.2820 - val_auc_1: 0.9527\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2697 - auc_1: 0.9545 - val_loss: 0.2817 - val_auc_1: 0.9527\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2706 - auc_1: 0.9552 - val_loss: 0.2814 - val_auc_1: 0.9527\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2671 - auc_1: 0.9554 - val_loss: 0.2813 - val_auc_1: 0.9528\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2695 - auc_1: 0.9543 - val_loss: 0.2812 - val_auc_1: 0.9529\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2723 - auc_1: 0.9539 - val_loss: 0.2813 - val_auc_1: 0.9529\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2657 - auc_1: 0.9549 - val_loss: 0.2814 - val_auc_1: 0.9528\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2616 - auc_1: 0.9580 - val_loss: 0.2814 - val_auc_1: 0.9529\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2630 - auc_1: 0.9574 - val_loss: 0.2813 - val_auc_1: 0.9530\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2718 - auc_1: 0.9538 - val_loss: 0.2811 - val_auc_1: 0.9526\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2643 - auc_1: 0.9565 - val_loss: 0.2809 - val_auc_1: 0.9527\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2590 - auc_1: 0.9583 - val_loss: 0.2809 - val_auc_1: 0.9528\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2716 - auc_1: 0.9547 - val_loss: 0.2809 - val_auc_1: 0.9528\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2705 - auc_1: 0.9538 - val_loss: 0.2808 - val_auc_1: 0.9529\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2648 - auc_1: 0.9564 - val_loss: 0.2808 - val_auc_1: 0.9530\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2621 - auc_1: 0.9579 - val_loss: 0.2806 - val_auc_1: 0.9530\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2719 - auc_1: 0.9538 - val_loss: 0.2804 - val_auc_1: 0.9531\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2622 - auc_1: 0.9576 - val_loss: 0.2803 - val_auc_1: 0.9531\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2625 - auc_1: 0.9571 - val_loss: 0.2801 - val_auc_1: 0.9531\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2728 - auc_1: 0.9535 - val_loss: 0.2800 - val_auc_1: 0.9530\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2714 - auc_1: 0.9542 - val_loss: 0.2800 - val_auc_1: 0.9530\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2656 - auc_1: 0.9561 - val_loss: 0.2798 - val_auc_1: 0.9531\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2684 - auc_1: 0.9546 - val_loss: 0.2797 - val_auc_1: 0.9531\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2610 - auc_1: 0.9573 - val_loss: 0.2797 - val_auc_1: 0.9530\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2655 - auc_1: 0.9555 - val_loss: 0.2797 - val_auc_1: 0.9530\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2698 - auc_1: 0.9547 - val_loss: 0.2793 - val_auc_1: 0.9531\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2692 - auc_1: 0.9542 - val_loss: 0.2789 - val_auc_1: 0.9531\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2570 - auc_1: 0.9589 - val_loss: 0.2788 - val_auc_1: 0.9532\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2678 - auc_1: 0.9552 - val_loss: 0.2786 - val_auc_1: 0.9532\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2604 - auc_1: 0.9569 - val_loss: 0.2783 - val_auc_1: 0.9532\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2654 - auc_1: 0.9560 - val_loss: 0.2781 - val_auc_1: 0.9533\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2651 - auc_1: 0.9560 - val_loss: 0.2780 - val_auc_1: 0.9532\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2617 - auc_1: 0.9572 - val_loss: 0.2780 - val_auc_1: 0.9532\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2637 - auc_1: 0.9564 - val_loss: 0.2777 - val_auc_1: 0.9533\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2610 - auc_1: 0.9572 - val_loss: 0.2775 - val_auc_1: 0.9535\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2593 - auc_1: 0.9577 - val_loss: 0.2775 - val_auc_1: 0.9535\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2587 - auc_1: 0.9583 - val_loss: 0.2777 - val_auc_1: 0.9535\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2594 - auc_1: 0.9583 - val_loss: 0.2778 - val_auc_1: 0.9534\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2587 - auc_1: 0.9581 - val_loss: 0.2782 - val_auc_1: 0.9535\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2629 - auc_1: 0.9569 - val_loss: 0.2786 - val_auc_1: 0.9535\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2616 - auc_1: 0.9571 - val_loss: 0.2784 - val_auc_1: 0.9535\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2598 - auc_1: 0.9576 - val_loss: 0.2780 - val_auc_1: 0.9536\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2573 - auc_1: 0.9585 - val_loss: 0.2776 - val_auc_1: 0.9537\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2648 - auc_1: 0.9558 - val_loss: 0.2776 - val_auc_1: 0.9537\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2545 - auc_1: 0.9603 - val_loss: 0.2775 - val_auc_1: 0.9536\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2579 - auc_1: 0.9586 - val_loss: 0.2777 - val_auc_1: 0.9536\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2545 - auc_1: 0.9598 - val_loss: 0.2780 - val_auc_1: 0.9536\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2561 - auc_1: 0.9596 - val_loss: 0.2780 - val_auc_1: 0.9535\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2603 - auc_1: 0.9585 - val_loss: 0.2779 - val_auc_1: 0.9535\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2571 - auc_1: 0.9589 - val_loss: 0.2779 - val_auc_1: 0.9534\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2543 - auc_1: 0.9599 - val_loss: 0.2779 - val_auc_1: 0.9534\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2593 - auc_1: 0.9587 - val_loss: 0.2782 - val_auc_1: 0.9534\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2569 - auc_1: 0.9584 - val_loss: 0.2784 - val_auc_1: 0.9533\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2561 - auc_1: 0.9590 - val_loss: 0.2784 - val_auc_1: 0.9532\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2569 - auc_1: 0.9589 - val_loss: 0.2784 - val_auc_1: 0.9532\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2645 - auc_1: 0.9559 - val_loss: 0.2783 - val_auc_1: 0.9533\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2556 - auc_1: 0.9590 - val_loss: 0.2785 - val_auc_1: 0.9533\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2521 - auc_1: 0.9603 - val_loss: 0.2787 - val_auc_1: 0.9534\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2601 - auc_1: 0.9581 - val_loss: 0.2792 - val_auc_1: 0.9534\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2541 - auc_1: 0.9596 - val_loss: 0.2792 - val_auc_1: 0.9534\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2559 - auc_1: 0.9594 - val_loss: 0.2789 - val_auc_1: 0.9535\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2539 - auc_1: 0.9596 - val_loss: 0.2788 - val_auc_1: 0.9534\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2559 - auc_1: 0.9594 - val_loss: 0.2789 - val_auc_1: 0.9533\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2530 - auc_1: 0.9601 - val_loss: 0.2787 - val_auc_1: 0.9532\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2506 - auc_1: 0.9613 - val_loss: 0.2781 - val_auc_1: 0.9531\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2617 - auc_1: 0.9568 - val_loss: 0.2777 - val_auc_1: 0.9532\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2609 - auc_1: 0.9575 - val_loss: 0.2777 - val_auc_1: 0.9532\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2536 - auc_1: 0.9596 - val_loss: 0.2776 - val_auc_1: 0.9532\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2488 - auc_1: 0.9615 - val_loss: 0.2778 - val_auc_1: 0.9533\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2536 - auc_1: 0.9601 - val_loss: 0.2779 - val_auc_1: 0.9533\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2505 - auc_1: 0.9609 - val_loss: 0.2778 - val_auc_1: 0.9534\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2465 - auc_1: 0.9632 - val_loss: 0.2778 - val_auc_1: 0.9536\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2467 - auc_1: 0.9623 - val_loss: 0.2776 - val_auc_1: 0.9537\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2494 - auc_1: 0.9609 - val_loss: 0.2773 - val_auc_1: 0.9537\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2617 - auc_1: 0.9570 - val_loss: 0.2771 - val_auc_1: 0.9537\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2516 - auc_1: 0.9606 - val_loss: 0.2769 - val_auc_1: 0.9538\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2538 - auc_1: 0.9592 - val_loss: 0.2767 - val_auc_1: 0.9538\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2543 - auc_1: 0.9598 - val_loss: 0.2765 - val_auc_1: 0.9537\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2461 - auc_1: 0.9622 - val_loss: 0.2766 - val_auc_1: 0.9538\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2520 - auc_1: 0.9603 - val_loss: 0.2765 - val_auc_1: 0.9538\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2479 - auc_1: 0.9617 - val_loss: 0.2767 - val_auc_1: 0.9537\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2438 - auc_1: 0.9636 - val_loss: 0.2767 - val_auc_1: 0.9536\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2507 - auc_1: 0.9612 - val_loss: 0.2765 - val_auc_1: 0.9537\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2427 - auc_1: 0.9635 - val_loss: 0.2761 - val_auc_1: 0.9538\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2458 - auc_1: 0.9621 - val_loss: 0.2759 - val_auc_1: 0.9539\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2518 - auc_1: 0.9596 - val_loss: 0.2758 - val_auc_1: 0.9540\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2518 - auc_1: 0.9601 - val_loss: 0.2759 - val_auc_1: 0.9540\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2461 - auc_1: 0.9621 - val_loss: 0.2758 - val_auc_1: 0.9538\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2532 - auc_1: 0.9606 - val_loss: 0.2757 - val_auc_1: 0.9538\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2426 - auc_1: 0.9634 - val_loss: 0.2757 - val_auc_1: 0.9537\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2500 - auc_1: 0.9608 - val_loss: 0.2754 - val_auc_1: 0.9538\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2514 - auc_1: 0.9605 - val_loss: 0.2752 - val_auc_1: 0.9538\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2476 - auc_1: 0.9616 - val_loss: 0.2749 - val_auc_1: 0.9538\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2505 - auc_1: 0.9605 - val_loss: 0.2750 - val_auc_1: 0.9538\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2402 - auc_1: 0.9642 - val_loss: 0.2749 - val_auc_1: 0.9539\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2459 - auc_1: 0.9626 - val_loss: 0.2750 - val_auc_1: 0.9540\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2509 - auc_1: 0.9607 - val_loss: 0.2749 - val_auc_1: 0.9540\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2510 - auc_1: 0.9610 - val_loss: 0.2751 - val_auc_1: 0.9541\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2471 - auc_1: 0.9620 - val_loss: 0.2748 - val_auc_1: 0.9542\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2500 - auc_1: 0.9605 - val_loss: 0.2745 - val_auc_1: 0.9542\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2442 - auc_1: 0.9627 - val_loss: 0.2743 - val_auc_1: 0.9543\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2400 - auc_1: 0.9645 - val_loss: 0.2744 - val_auc_1: 0.9543\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2372 - auc_1: 0.9645 - val_loss: 0.2745 - val_auc_1: 0.9542\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2371 - auc_1: 0.9656 - val_loss: 0.2745 - val_auc_1: 0.9543\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2489 - auc_1: 0.9617 - val_loss: 0.2742 - val_auc_1: 0.9545\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2465 - auc_1: 0.9620 - val_loss: 0.2739 - val_auc_1: 0.9546\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2423 - auc_1: 0.9632 - val_loss: 0.2740 - val_auc_1: 0.9546\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2500 - auc_1: 0.9607 - val_loss: 0.2744 - val_auc_1: 0.9545\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2410 - auc_1: 0.9634 - val_loss: 0.2746 - val_auc_1: 0.9545\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2452 - auc_1: 0.9625 - val_loss: 0.2746 - val_auc_1: 0.9545\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2513 - auc_1: 0.9602 - val_loss: 0.2746 - val_auc_1: 0.9545\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2523 - auc_1: 0.9605 - val_loss: 0.2749 - val_auc_1: 0.9545\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2491 - auc_1: 0.9612 - val_loss: 0.2756 - val_auc_1: 0.9544\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2418 - auc_1: 0.9629 - val_loss: 0.2757 - val_auc_1: 0.9543\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2494 - auc_1: 0.9613 - val_loss: 0.2756 - val_auc_1: 0.9544\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2425 - auc_1: 0.9633 - val_loss: 0.2753 - val_auc_1: 0.9544\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2388 - auc_1: 0.9644 - val_loss: 0.2750 - val_auc_1: 0.9543\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2454 - auc_1: 0.9624 - val_loss: 0.2751 - val_auc_1: 0.9543\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2428 - auc_1: 0.9635 - val_loss: 0.2751 - val_auc_1: 0.9543\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2451 - auc_1: 0.9626 - val_loss: 0.2750 - val_auc_1: 0.9544\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2490 - auc_1: 0.9612 - val_loss: 0.2746 - val_auc_1: 0.9545\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2495 - auc_1: 0.9606 - val_loss: 0.2742 - val_auc_1: 0.9546\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2510 - auc_1: 0.9606 - val_loss: 0.2739 - val_auc_1: 0.9547\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2415 - auc_1: 0.9645 - val_loss: 0.2738 - val_auc_1: 0.9546\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2466 - auc_1: 0.9622 - val_loss: 0.2735 - val_auc_1: 0.9548\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2426 - auc_1: 0.9631 - val_loss: 0.2732 - val_auc_1: 0.9548\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2428 - auc_1: 0.9629 - val_loss: 0.2727 - val_auc_1: 0.9550\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2451 - auc_1: 0.9626 - val_loss: 0.2719 - val_auc_1: 0.9557\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2435 - auc_1: 0.9631 - val_loss: 0.2714 - val_auc_1: 0.9559\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2447 - auc_1: 0.9627 - val_loss: 0.2707 - val_auc_1: 0.9560\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2454 - auc_1: 0.9623 - val_loss: 0.2701 - val_auc_1: 0.9562\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2461 - auc_1: 0.9619 - val_loss: 0.2696 - val_auc_1: 0.9563\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2467 - auc_1: 0.9624 - val_loss: 0.2689 - val_auc_1: 0.9565\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2449 - auc_1: 0.9623 - val_loss: 0.2686 - val_auc_1: 0.9566\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2434 - auc_1: 0.9633 - val_loss: 0.2685 - val_auc_1: 0.9566\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2453 - auc_1: 0.9624 - val_loss: 0.2689 - val_auc_1: 0.9566\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2414 - auc_1: 0.9636 - val_loss: 0.2693 - val_auc_1: 0.9565\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2440 - auc_1: 0.9625 - val_loss: 0.2697 - val_auc_1: 0.9564\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2454 - auc_1: 0.9622 - val_loss: 0.2699 - val_auc_1: 0.9564\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2486 - auc_1: 0.9616 - val_loss: 0.2700 - val_auc_1: 0.9565\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2470 - auc_1: 0.9616 - val_loss: 0.2699 - val_auc_1: 0.9566\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2384 - auc_1: 0.9647 - val_loss: 0.2698 - val_auc_1: 0.9562\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2390 - auc_1: 0.9641 - val_loss: 0.2700 - val_auc_1: 0.9561\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2423 - auc_1: 0.9630 - val_loss: 0.2704 - val_auc_1: 0.9561\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2377 - auc_1: 0.9643 - val_loss: 0.2706 - val_auc_1: 0.9560\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2367 - auc_1: 0.9653 - val_loss: 0.2705 - val_auc_1: 0.9560\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2452 - auc_1: 0.9625 - val_loss: 0.2704 - val_auc_1: 0.9559\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2448 - auc_1: 0.9624 - val_loss: 0.2702 - val_auc_1: 0.9559\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2413 - auc_1: 0.9634 - val_loss: 0.2704 - val_auc_1: 0.9559\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2342 - auc_1: 0.9657 - val_loss: 0.2706 - val_auc_1: 0.9558\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2369 - auc_1: 0.9652 - val_loss: 0.2708 - val_auc_1: 0.9553\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2417 - auc_1: 0.9634 - val_loss: 0.2709 - val_auc_1: 0.9548\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2375 - auc_1: 0.9644 - val_loss: 0.2714 - val_auc_1: 0.9548\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2471 - auc_1: 0.9622 - val_loss: 0.2720 - val_auc_1: 0.9554\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2428 - auc_1: 0.9632 - val_loss: 0.2718 - val_auc_1: 0.9559\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2396 - auc_1: 0.9641 - val_loss: 0.2713 - val_auc_1: 0.9561\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2358 - auc_1: 0.9654 - val_loss: 0.2711 - val_auc_1: 0.9562\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2444 - auc_1: 0.9626 - val_loss: 0.2708 - val_auc_1: 0.9562\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2404 - auc_1: 0.9636 - val_loss: 0.2702 - val_auc_1: 0.9564\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2413 - auc_1: 0.9633 - val_loss: 0.2696 - val_auc_1: 0.9564\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2384 - auc_1: 0.9639 - val_loss: 0.2693 - val_auc_1: 0.9564\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2354 - auc_1: 0.9658 - val_loss: 0.2692 - val_auc_1: 0.9563\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2370 - auc_1: 0.9642 - val_loss: 0.2692 - val_auc_1: 0.9563\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2398 - auc_1: 0.9640 - val_loss: 0.2690 - val_auc_1: 0.9564\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2383 - auc_1: 0.9643 - val_loss: 0.2689 - val_auc_1: 0.9565\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2350 - auc_1: 0.9649 - val_loss: 0.2688 - val_auc_1: 0.9566\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2335 - auc_1: 0.9659 - val_loss: 0.2687 - val_auc_1: 0.9566\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2394 - auc_1: 0.9642 - val_loss: 0.2684 - val_auc_1: 0.9566\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2382 - auc_1: 0.9649 - val_loss: 0.2681 - val_auc_1: 0.9567\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2431 - auc_1: 0.9632 - val_loss: 0.2680 - val_auc_1: 0.9567\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2363 - auc_1: 0.9650 - val_loss: 0.2676 - val_auc_1: 0.9567\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2451 - auc_1: 0.9624 - val_loss: 0.2673 - val_auc_1: 0.9567\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2390 - auc_1: 0.9643 - val_loss: 0.2673 - val_auc_1: 0.9566\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2392 - auc_1: 0.9643 - val_loss: 0.2675 - val_auc_1: 0.9566\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2369 - auc_1: 0.9650 - val_loss: 0.2675 - val_auc_1: 0.9566\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2382 - auc_1: 0.9649 - val_loss: 0.2672 - val_auc_1: 0.9567\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2341 - auc_1: 0.9661 - val_loss: 0.2671 - val_auc_1: 0.9574\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2393 - auc_1: 0.9640 - val_loss: 0.2670 - val_auc_1: 0.9570\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2341 - auc_1: 0.9659 - val_loss: 0.2671 - val_auc_1: 0.9570\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2350 - auc_1: 0.9654 - val_loss: 0.2669 - val_auc_1: 0.9571\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2379 - auc_1: 0.9644 - val_loss: 0.2667 - val_auc_1: 0.9566\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2384 - auc_1: 0.9642 - val_loss: 0.2664 - val_auc_1: 0.9567\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2359 - auc_1: 0.9650 - val_loss: 0.2662 - val_auc_1: 0.9568\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2435 - auc_1: 0.9624 - val_loss: 0.2662 - val_auc_1: 0.9567\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2345 - auc_1: 0.9654 - val_loss: 0.2663 - val_auc_1: 0.9568\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2430 - auc_1: 0.9624 - val_loss: 0.2663 - val_auc_1: 0.9569\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2315 - auc_1: 0.9660 - val_loss: 0.2664 - val_auc_1: 0.9570\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2301 - auc_1: 0.9670 - val_loss: 0.2667 - val_auc_1: 0.9570\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2355 - auc_1: 0.9652 - val_loss: 0.2668 - val_auc_1: 0.9570\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2420 - auc_1: 0.9635 - val_loss: 0.2670 - val_auc_1: 0.9571\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2388 - auc_1: 0.9642 - val_loss: 0.2673 - val_auc_1: 0.9572\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2372 - auc_1: 0.9647 - val_loss: 0.2677 - val_auc_1: 0.9572\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2359 - auc_1: 0.9648 - val_loss: 0.2684 - val_auc_1: 0.9567\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2288 - auc_1: 0.9675 - val_loss: 0.2689 - val_auc_1: 0.9566\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2386 - auc_1: 0.9646 - val_loss: 0.2690 - val_auc_1: 0.9566\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2357 - auc_1: 0.9650 - val_loss: 0.2688 - val_auc_1: 0.9566\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2315 - auc_1: 0.9664 - val_loss: 0.2681 - val_auc_1: 0.9571\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2402 - auc_1: 0.9637 - val_loss: 0.2677 - val_auc_1: 0.9572\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2287 - auc_1: 0.9670 - val_loss: 0.2674 - val_auc_1: 0.9572\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2441 - auc_1: 0.9626 - val_loss: 0.2670 - val_auc_1: 0.9572\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2338 - auc_1: 0.9656 - val_loss: 0.2664 - val_auc_1: 0.9574\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2347 - auc_1: 0.9654 - val_loss: 0.2658 - val_auc_1: 0.9574\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2282 - auc_1: 0.9676 - val_loss: 0.2655 - val_auc_1: 0.9574\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2319 - auc_1: 0.9660 - val_loss: 0.2650 - val_auc_1: 0.9574\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2319 - auc_1: 0.9662 - val_loss: 0.2648 - val_auc_1: 0.9574\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2349 - auc_1: 0.9657 - val_loss: 0.2650 - val_auc_1: 0.9573\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2347 - auc_1: 0.9653 - val_loss: 0.2651 - val_auc_1: 0.9574\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2278 - auc_1: 0.9677 - val_loss: 0.2653 - val_auc_1: 0.9574\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2333 - auc_1: 0.9657 - val_loss: 0.2656 - val_auc_1: 0.9569\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2260 - auc_1: 0.9684 - val_loss: 0.2658 - val_auc_1: 0.9570\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2346 - auc_1: 0.9652 - val_loss: 0.2662 - val_auc_1: 0.9570\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2291 - auc_1: 0.9666 - val_loss: 0.2665 - val_auc_1: 0.9570\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2296 - auc_1: 0.9667 - val_loss: 0.2666 - val_auc_1: 0.9571\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2317 - auc_1: 0.9665 - val_loss: 0.2667 - val_auc_1: 0.9572\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2287 - auc_1: 0.9668 - val_loss: 0.2667 - val_auc_1: 0.9572\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2290 - auc_1: 0.9681 - val_loss: 0.2663 - val_auc_1: 0.9572\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2373 - auc_1: 0.9644 - val_loss: 0.2660 - val_auc_1: 0.9578\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2286 - auc_1: 0.9677 - val_loss: 0.2657 - val_auc_1: 0.9578\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2337 - auc_1: 0.9654 - val_loss: 0.2651 - val_auc_1: 0.9572\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2356 - auc_1: 0.9653 - val_loss: 0.2646 - val_auc_1: 0.9571\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2336 - auc_1: 0.9656 - val_loss: 0.2644 - val_auc_1: 0.9578\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2265 - auc_1: 0.9677 - val_loss: 0.2642 - val_auc_1: 0.9577\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2315 - auc_1: 0.9662 - val_loss: 0.2642 - val_auc_1: 0.9578\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2291 - auc_1: 0.9672 - val_loss: 0.2646 - val_auc_1: 0.9573\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2376 - auc_1: 0.9641 - val_loss: 0.2648 - val_auc_1: 0.9573\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2388 - auc_1: 0.9643 - val_loss: 0.2651 - val_auc_1: 0.9573\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2265 - auc_1: 0.9679 - val_loss: 0.2652 - val_auc_1: 0.9573\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2290 - auc_1: 0.9669 - val_loss: 0.2653 - val_auc_1: 0.9578\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2364 - auc_1: 0.9649 - val_loss: 0.2657 - val_auc_1: 0.9577\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2306 - auc_1: 0.9667 - val_loss: 0.2659 - val_auc_1: 0.9576\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2290 - auc_1: 0.9666 - val_loss: 0.2659 - val_auc_1: 0.9576\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2312 - auc_1: 0.9665 - val_loss: 0.2659 - val_auc_1: 0.9571\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2278 - auc_1: 0.9676 - val_loss: 0.2657 - val_auc_1: 0.9572\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2335 - auc_1: 0.9658 - val_loss: 0.2654 - val_auc_1: 0.9572\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2261 - auc_1: 0.9676 - val_loss: 0.2651 - val_auc_1: 0.9578\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2342 - auc_1: 0.9659 - val_loss: 0.2652 - val_auc_1: 0.9579\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2290 - auc_1: 0.9674 - val_loss: 0.2653 - val_auc_1: 0.9574\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2264 - auc_1: 0.9674 - val_loss: 0.2654 - val_auc_1: 0.9574\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2285 - auc_1: 0.9670 - val_loss: 0.2650 - val_auc_1: 0.9575\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2312 - auc_1: 0.9660 - val_loss: 0.2647 - val_auc_1: 0.9576\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2341 - auc_1: 0.9654 - val_loss: 0.2645 - val_auc_1: 0.9575\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2259 - auc_1: 0.9676 - val_loss: 0.2645 - val_auc_1: 0.9576\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2279 - auc_1: 0.9676 - val_loss: 0.2644 - val_auc_1: 0.9576\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2295 - auc_1: 0.9668 - val_loss: 0.2640 - val_auc_1: 0.9576\n",
      "Epoch 469/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2270 - auc_1: 0.9680 - val_loss: 0.2638 - val_auc_1: 0.9581\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2408 - auc_1: 0.9639 - val_loss: 0.2638 - val_auc_1: 0.9581\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2324 - auc_1: 0.9655 - val_loss: 0.2641 - val_auc_1: 0.9580\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2352 - auc_1: 0.9653 - val_loss: 0.2645 - val_auc_1: 0.9581\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2280 - auc_1: 0.9678 - val_loss: 0.2649 - val_auc_1: 0.9576\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2275 - auc_1: 0.9676 - val_loss: 0.2655 - val_auc_1: 0.9575\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2339 - auc_1: 0.9651 - val_loss: 0.2653 - val_auc_1: 0.9576\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2275 - auc_1: 0.9678 - val_loss: 0.2651 - val_auc_1: 0.9576\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2264 - auc_1: 0.9678 - val_loss: 0.2648 - val_auc_1: 0.9577\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2348 - auc_1: 0.9652 - val_loss: 0.2647 - val_auc_1: 0.9582\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2324 - auc_1: 0.9670 - val_loss: 0.2647 - val_auc_1: 0.9577\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2412 - auc_1: 0.9640 - val_loss: 0.2645 - val_auc_1: 0.9584\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2349 - auc_1: 0.9652 - val_loss: 0.2648 - val_auc_1: 0.9578\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2267 - auc_1: 0.9679 - val_loss: 0.2646 - val_auc_1: 0.9584\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2221 - auc_1: 0.9691 - val_loss: 0.2640 - val_auc_1: 0.9585\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2356 - auc_1: 0.9648 - val_loss: 0.2633 - val_auc_1: 0.9585\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2324 - auc_1: 0.9660 - val_loss: 0.2627 - val_auc_1: 0.9586\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2323 - auc_1: 0.9658 - val_loss: 0.2627 - val_auc_1: 0.9587\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2292 - auc_1: 0.9675 - val_loss: 0.2628 - val_auc_1: 0.9586\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2264 - auc_1: 0.9677 - val_loss: 0.2632 - val_auc_1: 0.9585\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2206 - auc_1: 0.9699 - val_loss: 0.2637 - val_auc_1: 0.9585\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2232 - auc_1: 0.9688 - val_loss: 0.2640 - val_auc_1: 0.9585\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2249 - auc_1: 0.9680 - val_loss: 0.2641 - val_auc_1: 0.9580\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2253 - auc_1: 0.9679 - val_loss: 0.2640 - val_auc_1: 0.9580\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2338 - auc_1: 0.9656 - val_loss: 0.2641 - val_auc_1: 0.9586\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2273 - auc_1: 0.9679 - val_loss: 0.2642 - val_auc_1: 0.9580\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2238 - auc_1: 0.9691 - val_loss: 0.2638 - val_auc_1: 0.9581\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2224 - auc_1: 0.9696 - val_loss: 0.2635 - val_auc_1: 0.9582\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2257 - auc_1: 0.9686 - val_loss: 0.2633 - val_auc_1: 0.9582\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2253 - auc_1: 0.9682 - val_loss: 0.2633 - val_auc_1: 0.9582\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2263 - auc_1: 0.9671 - val_loss: 0.2632 - val_auc_1: 0.9582\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2240 - auc_1: 0.9682 - val_loss: 0.2634 - val_auc_1: 0.9582\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_1, y_train_1, \n",
    "          epochs=500, \n",
    "          batch_size=1000, \n",
    "          validation_data=(X_test_1, y_test_1),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82274dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     1     2   3     4     5     6     7     8     9   ...  47    48  \\\n",
      "0  0.00  0.64  0.64   0  0.32  0.00  0.00  0.00  0.00  0.00  ...   0  0.00   \n",
      "1  0.21  0.28  0.50   0  0.14  0.28  0.21  0.07  0.00  0.94  ...   0  0.00   \n",
      "2  0.06  0.00  0.71   0  1.23  0.19  0.19  0.12  0.64  0.25  ...   0  0.01   \n",
      "3  0.00  0.00  0.00   0  0.63  0.00  0.31  0.63  0.31  0.63  ...   0  0.00   \n",
      "4  0.00  0.00  0.00   0  0.63  0.00  0.31  0.63  0.31  0.63  ...   0  0.00   \n",
      "\n",
      "      49  50     51     52     53     54   55    56  \n",
      "0  0.000   0  0.778  0.000  0.000  3.756   61   278  \n",
      "1  0.132   0  0.372  0.180  0.048  5.114  101  1028  \n",
      "2  0.143   0  0.276  0.184  0.010  9.821  485  2259  \n",
      "3  0.137   0  0.137  0.000  0.000  3.537   40   191  \n",
      "4  0.135   0  0.135  0.000  0.000  3.537   40   191  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "# load the test data\n",
    "test_data = pd.read_csv(\"../test/test.csv\",  sep = ',', header= None )\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6fc1b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 57)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24bb37e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f0485c75290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f0485c75290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 47), found shape=(None, 57)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14712/3493834124.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Predict the class of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\u001b[0m\u001b[1;32m    264\u001b[0m                              \u001b[0;34m'incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                              \u001b[0;34mf'expected shape={spec.shape}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 47), found shape=(None, 57)"
     ]
    }
   ],
   "source": [
    "#Predict the class of data\n",
    "pred=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14499b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664d11f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
